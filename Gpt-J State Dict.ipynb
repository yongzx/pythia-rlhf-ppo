{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de1f9a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "from huggingface_hub import snapshot_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33e9b5c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ab52beef6ff4d1c8e8d94dd7db3aaa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gptj = AutoModelForCausalLM.from_pretrained(\"Dahoas/pythia-6B-static-sft\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "046de240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c48caa30ced4324b1954ade2d6a2332",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "602b8ee5ad7d4fe8987b6dff225c23c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading hf_ckpt.pt:   0%|          | 0.00/23.5G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "directory = snapshot_download(\"Dahoas/gptj-rm-static\", revision=\"676bfd4d\")\n",
    "for fpath in os.listdir(directory):\n",
    "    if fpath.endswith(\".pt\") or fpath.endswith(\".bin\"):\n",
    "        checkpoint = os.path.join(directory, fpath)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "06f9184a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gptj_state = gptj.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4b94e607",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f95d82f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gptj_rm_state = torch.load(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c1ae91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba78fb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gptj_rm_modified_state = []\n",
    "for key, value in gptj_rm_state.items():\n",
    "    gptj_rm_modified_state.append((re.sub('^(model\\.)', '', key), value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84e9a5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "gptj_rm_modified_state = OrderedDict(gptj_rm_modified_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b7d9f05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50400, 4096])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gptj_state['lm_head.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b1fe4405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4096])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gptj_rm_state['v_head.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "40cb1e96",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer.wte.weight\n",
      "transformer.h.0.ln_1.weight\n",
      "transformer.h.0.ln_1.bias\n",
      "transformer.h.0.attn.k_proj.weight\n",
      "transformer.h.0.attn.v_proj.weight\n",
      "transformer.h.0.attn.q_proj.weight\n",
      "transformer.h.0.attn.out_proj.weight\n",
      "transformer.h.0.mlp.fc_in.weight\n",
      "transformer.h.0.mlp.fc_in.bias\n",
      "transformer.h.0.mlp.fc_out.weight\n",
      "transformer.h.0.mlp.fc_out.bias\n",
      "transformer.h.1.ln_1.weight\n",
      "transformer.h.1.ln_1.bias\n",
      "transformer.h.1.attn.k_proj.weight\n",
      "transformer.h.1.attn.v_proj.weight\n",
      "transformer.h.1.attn.q_proj.weight\n",
      "transformer.h.1.attn.out_proj.weight\n",
      "transformer.h.1.mlp.fc_in.weight\n",
      "transformer.h.1.mlp.fc_in.bias\n",
      "transformer.h.1.mlp.fc_out.weight\n",
      "transformer.h.1.mlp.fc_out.bias\n",
      "transformer.h.2.ln_1.weight\n",
      "transformer.h.2.ln_1.bias\n",
      "transformer.h.2.attn.k_proj.weight\n",
      "transformer.h.2.attn.v_proj.weight\n",
      "transformer.h.2.attn.q_proj.weight\n",
      "transformer.h.2.attn.out_proj.weight\n",
      "transformer.h.2.mlp.fc_in.weight\n",
      "transformer.h.2.mlp.fc_in.bias\n",
      "transformer.h.2.mlp.fc_out.weight\n",
      "transformer.h.2.mlp.fc_out.bias\n",
      "transformer.h.3.ln_1.weight\n",
      "transformer.h.3.ln_1.bias\n",
      "transformer.h.3.attn.k_proj.weight\n",
      "transformer.h.3.attn.v_proj.weight\n",
      "transformer.h.3.attn.q_proj.weight\n",
      "transformer.h.3.attn.out_proj.weight\n",
      "transformer.h.3.mlp.fc_in.weight\n",
      "transformer.h.3.mlp.fc_in.bias\n",
      "transformer.h.3.mlp.fc_out.weight\n",
      "transformer.h.3.mlp.fc_out.bias\n",
      "transformer.h.4.ln_1.weight\n",
      "transformer.h.4.ln_1.bias\n",
      "transformer.h.4.attn.k_proj.weight\n",
      "transformer.h.4.attn.v_proj.weight\n",
      "transformer.h.4.attn.q_proj.weight\n",
      "transformer.h.4.attn.out_proj.weight\n",
      "transformer.h.4.mlp.fc_in.weight\n",
      "transformer.h.4.mlp.fc_in.bias\n",
      "transformer.h.4.mlp.fc_out.weight\n",
      "transformer.h.4.mlp.fc_out.bias\n",
      "transformer.h.5.ln_1.weight\n",
      "transformer.h.5.ln_1.bias\n",
      "transformer.h.5.attn.k_proj.weight\n",
      "transformer.h.5.attn.v_proj.weight\n",
      "transformer.h.5.attn.q_proj.weight\n",
      "transformer.h.5.attn.out_proj.weight\n",
      "transformer.h.5.mlp.fc_in.weight\n",
      "transformer.h.5.mlp.fc_in.bias\n",
      "transformer.h.5.mlp.fc_out.weight\n",
      "transformer.h.5.mlp.fc_out.bias\n",
      "transformer.h.6.ln_1.weight\n",
      "transformer.h.6.ln_1.bias\n",
      "transformer.h.6.attn.k_proj.weight\n",
      "transformer.h.6.attn.v_proj.weight\n",
      "transformer.h.6.attn.q_proj.weight\n",
      "transformer.h.6.attn.out_proj.weight\n",
      "transformer.h.6.mlp.fc_in.weight\n",
      "transformer.h.6.mlp.fc_in.bias\n",
      "transformer.h.6.mlp.fc_out.weight\n",
      "transformer.h.6.mlp.fc_out.bias\n",
      "transformer.h.7.ln_1.weight\n",
      "transformer.h.7.ln_1.bias\n",
      "transformer.h.7.attn.k_proj.weight\n",
      "transformer.h.7.attn.v_proj.weight\n",
      "transformer.h.7.attn.q_proj.weight\n",
      "transformer.h.7.attn.out_proj.weight\n",
      "transformer.h.7.mlp.fc_in.weight\n",
      "transformer.h.7.mlp.fc_in.bias\n",
      "transformer.h.7.mlp.fc_out.weight\n",
      "transformer.h.7.mlp.fc_out.bias\n",
      "transformer.h.8.ln_1.weight\n",
      "transformer.h.8.ln_1.bias\n",
      "transformer.h.8.attn.k_proj.weight\n",
      "transformer.h.8.attn.v_proj.weight\n",
      "transformer.h.8.attn.q_proj.weight\n",
      "transformer.h.8.attn.out_proj.weight\n",
      "transformer.h.8.mlp.fc_in.weight\n",
      "transformer.h.8.mlp.fc_in.bias\n",
      "transformer.h.8.mlp.fc_out.weight\n",
      "transformer.h.8.mlp.fc_out.bias\n",
      "transformer.h.9.ln_1.weight\n",
      "transformer.h.9.ln_1.bias\n",
      "transformer.h.9.attn.k_proj.weight\n",
      "transformer.h.9.attn.v_proj.weight\n",
      "transformer.h.9.attn.q_proj.weight\n",
      "transformer.h.9.attn.out_proj.weight\n",
      "transformer.h.9.mlp.fc_in.weight\n",
      "transformer.h.9.mlp.fc_in.bias\n",
      "transformer.h.9.mlp.fc_out.weight\n",
      "transformer.h.9.mlp.fc_out.bias\n",
      "transformer.h.10.ln_1.weight\n",
      "transformer.h.10.ln_1.bias\n",
      "transformer.h.10.attn.k_proj.weight\n",
      "transformer.h.10.attn.v_proj.weight\n",
      "transformer.h.10.attn.q_proj.weight\n",
      "transformer.h.10.attn.out_proj.weight\n",
      "transformer.h.10.mlp.fc_in.weight\n",
      "transformer.h.10.mlp.fc_in.bias\n",
      "transformer.h.10.mlp.fc_out.weight\n",
      "transformer.h.10.mlp.fc_out.bias\n",
      "transformer.h.11.ln_1.weight\n",
      "transformer.h.11.ln_1.bias\n",
      "transformer.h.11.attn.k_proj.weight\n",
      "transformer.h.11.attn.v_proj.weight\n",
      "transformer.h.11.attn.q_proj.weight\n",
      "transformer.h.11.attn.out_proj.weight\n",
      "transformer.h.11.mlp.fc_in.weight\n",
      "transformer.h.11.mlp.fc_in.bias\n",
      "transformer.h.11.mlp.fc_out.weight\n",
      "transformer.h.11.mlp.fc_out.bias\n",
      "transformer.h.12.ln_1.weight\n",
      "transformer.h.12.ln_1.bias\n",
      "transformer.h.12.attn.k_proj.weight\n",
      "transformer.h.12.attn.v_proj.weight\n",
      "transformer.h.12.attn.q_proj.weight\n",
      "transformer.h.12.attn.out_proj.weight\n",
      "transformer.h.12.mlp.fc_in.weight\n",
      "transformer.h.12.mlp.fc_in.bias\n",
      "transformer.h.12.mlp.fc_out.weight\n",
      "transformer.h.12.mlp.fc_out.bias\n",
      "transformer.h.13.ln_1.weight\n",
      "transformer.h.13.ln_1.bias\n",
      "transformer.h.13.attn.k_proj.weight\n",
      "transformer.h.13.attn.v_proj.weight\n",
      "transformer.h.13.attn.q_proj.weight\n",
      "transformer.h.13.attn.out_proj.weight\n",
      "transformer.h.13.mlp.fc_in.weight\n",
      "transformer.h.13.mlp.fc_in.bias\n",
      "transformer.h.13.mlp.fc_out.weight\n",
      "transformer.h.13.mlp.fc_out.bias\n",
      "transformer.h.14.ln_1.weight\n",
      "transformer.h.14.ln_1.bias\n",
      "transformer.h.14.attn.k_proj.weight\n",
      "transformer.h.14.attn.v_proj.weight\n",
      "transformer.h.14.attn.q_proj.weight\n",
      "transformer.h.14.attn.out_proj.weight\n",
      "transformer.h.14.mlp.fc_in.weight\n",
      "transformer.h.14.mlp.fc_in.bias\n",
      "transformer.h.14.mlp.fc_out.weight\n",
      "transformer.h.14.mlp.fc_out.bias\n",
      "transformer.h.15.ln_1.weight\n",
      "transformer.h.15.ln_1.bias\n",
      "transformer.h.15.attn.k_proj.weight\n",
      "transformer.h.15.attn.v_proj.weight\n",
      "transformer.h.15.attn.q_proj.weight\n",
      "transformer.h.15.attn.out_proj.weight\n",
      "transformer.h.15.mlp.fc_in.weight\n",
      "transformer.h.15.mlp.fc_in.bias\n",
      "transformer.h.15.mlp.fc_out.weight\n",
      "transformer.h.15.mlp.fc_out.bias\n",
      "transformer.h.16.ln_1.weight\n",
      "transformer.h.16.ln_1.bias\n",
      "transformer.h.16.attn.k_proj.weight\n",
      "transformer.h.16.attn.v_proj.weight\n",
      "transformer.h.16.attn.q_proj.weight\n",
      "transformer.h.16.attn.out_proj.weight\n",
      "transformer.h.16.mlp.fc_in.weight\n",
      "transformer.h.16.mlp.fc_in.bias\n",
      "transformer.h.16.mlp.fc_out.weight\n",
      "transformer.h.16.mlp.fc_out.bias\n",
      "transformer.h.17.ln_1.weight\n",
      "transformer.h.17.ln_1.bias\n",
      "transformer.h.17.attn.k_proj.weight\n",
      "transformer.h.17.attn.v_proj.weight\n",
      "transformer.h.17.attn.q_proj.weight\n",
      "transformer.h.17.attn.out_proj.weight\n",
      "transformer.h.17.mlp.fc_in.weight\n",
      "transformer.h.17.mlp.fc_in.bias\n",
      "transformer.h.17.mlp.fc_out.weight\n",
      "transformer.h.17.mlp.fc_out.bias\n",
      "transformer.h.18.ln_1.weight\n",
      "transformer.h.18.ln_1.bias\n",
      "transformer.h.18.attn.k_proj.weight\n",
      "transformer.h.18.attn.v_proj.weight\n",
      "transformer.h.18.attn.q_proj.weight\n",
      "transformer.h.18.attn.out_proj.weight\n",
      "transformer.h.18.mlp.fc_in.weight\n",
      "transformer.h.18.mlp.fc_in.bias\n",
      "transformer.h.18.mlp.fc_out.weight\n",
      "transformer.h.18.mlp.fc_out.bias\n",
      "transformer.h.19.ln_1.weight\n",
      "transformer.h.19.ln_1.bias\n",
      "transformer.h.19.attn.k_proj.weight\n",
      "transformer.h.19.attn.v_proj.weight\n",
      "transformer.h.19.attn.q_proj.weight\n",
      "transformer.h.19.attn.out_proj.weight\n",
      "transformer.h.19.mlp.fc_in.weight\n",
      "transformer.h.19.mlp.fc_in.bias\n",
      "transformer.h.19.mlp.fc_out.weight\n",
      "transformer.h.19.mlp.fc_out.bias\n",
      "transformer.h.20.ln_1.weight\n",
      "transformer.h.20.ln_1.bias\n",
      "transformer.h.20.attn.k_proj.weight\n",
      "transformer.h.20.attn.v_proj.weight\n",
      "transformer.h.20.attn.q_proj.weight\n",
      "transformer.h.20.attn.out_proj.weight\n",
      "transformer.h.20.mlp.fc_in.weight\n",
      "transformer.h.20.mlp.fc_in.bias\n",
      "transformer.h.20.mlp.fc_out.weight\n",
      "transformer.h.20.mlp.fc_out.bias\n",
      "transformer.h.21.ln_1.weight\n",
      "transformer.h.21.ln_1.bias\n",
      "transformer.h.21.attn.k_proj.weight\n",
      "transformer.h.21.attn.v_proj.weight\n",
      "transformer.h.21.attn.q_proj.weight\n",
      "transformer.h.21.attn.out_proj.weight\n",
      "transformer.h.21.mlp.fc_in.weight\n",
      "transformer.h.21.mlp.fc_in.bias\n",
      "transformer.h.21.mlp.fc_out.weight\n",
      "transformer.h.21.mlp.fc_out.bias\n",
      "transformer.h.22.ln_1.weight\n",
      "transformer.h.22.ln_1.bias\n",
      "transformer.h.22.attn.k_proj.weight\n",
      "transformer.h.22.attn.v_proj.weight\n",
      "transformer.h.22.attn.q_proj.weight\n",
      "transformer.h.22.attn.out_proj.weight\n",
      "transformer.h.22.mlp.fc_in.weight\n",
      "transformer.h.22.mlp.fc_in.bias\n",
      "transformer.h.22.mlp.fc_out.weight\n",
      "transformer.h.22.mlp.fc_out.bias\n",
      "transformer.h.23.ln_1.weight\n",
      "transformer.h.23.ln_1.bias\n",
      "transformer.h.23.attn.k_proj.weight\n",
      "transformer.h.23.attn.v_proj.weight\n",
      "transformer.h.23.attn.q_proj.weight\n",
      "transformer.h.23.attn.out_proj.weight\n",
      "transformer.h.23.mlp.fc_in.weight\n",
      "transformer.h.23.mlp.fc_in.bias\n",
      "transformer.h.23.mlp.fc_out.weight\n",
      "transformer.h.23.mlp.fc_out.bias\n",
      "transformer.h.24.ln_1.weight\n",
      "transformer.h.24.ln_1.bias\n",
      "transformer.h.24.attn.k_proj.weight\n",
      "transformer.h.24.attn.v_proj.weight\n",
      "transformer.h.24.attn.q_proj.weight\n",
      "transformer.h.24.attn.out_proj.weight\n",
      "transformer.h.24.mlp.fc_in.weight\n",
      "transformer.h.24.mlp.fc_in.bias\n",
      "transformer.h.24.mlp.fc_out.weight\n",
      "transformer.h.24.mlp.fc_out.bias\n",
      "transformer.h.25.ln_1.weight\n",
      "transformer.h.25.ln_1.bias\n",
      "transformer.h.25.attn.k_proj.weight\n",
      "transformer.h.25.attn.v_proj.weight\n",
      "transformer.h.25.attn.q_proj.weight\n",
      "transformer.h.25.attn.out_proj.weight\n",
      "transformer.h.25.mlp.fc_in.weight\n",
      "transformer.h.25.mlp.fc_in.bias\n",
      "transformer.h.25.mlp.fc_out.weight\n",
      "transformer.h.25.mlp.fc_out.bias\n",
      "transformer.h.26.ln_1.weight\n",
      "transformer.h.26.ln_1.bias\n",
      "transformer.h.26.attn.k_proj.weight\n",
      "transformer.h.26.attn.v_proj.weight\n",
      "transformer.h.26.attn.q_proj.weight\n",
      "transformer.h.26.attn.out_proj.weight\n",
      "transformer.h.26.mlp.fc_in.weight\n",
      "transformer.h.26.mlp.fc_in.bias\n",
      "transformer.h.26.mlp.fc_out.weight\n",
      "transformer.h.26.mlp.fc_out.bias\n",
      "transformer.h.27.ln_1.weight\n",
      "transformer.h.27.ln_1.bias\n",
      "transformer.h.27.attn.k_proj.weight\n",
      "transformer.h.27.attn.v_proj.weight\n",
      "transformer.h.27.attn.q_proj.weight\n",
      "transformer.h.27.attn.out_proj.weight\n",
      "transformer.h.27.mlp.fc_in.weight\n",
      "transformer.h.27.mlp.fc_in.bias\n",
      "transformer.h.27.mlp.fc_out.weight\n",
      "transformer.h.27.mlp.fc_out.bias\n",
      "transformer.ln_f.weight\n",
      "transformer.ln_f.bias\n",
      "lm_head.weight\n",
      "lm_head.bias\n"
     ]
    }
   ],
   "source": [
    "for key in gptj_state.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d9bc278c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.transformer.wte.weight\n",
      "model.transformer.h.0.ln_1.weight\n",
      "model.transformer.h.0.ln_1.bias\n",
      "model.transformer.h.0.attn.bias\n",
      "model.transformer.h.0.attn.masked_bias\n",
      "model.transformer.h.0.attn.k_proj.weight\n",
      "model.transformer.h.0.attn.v_proj.weight\n",
      "model.transformer.h.0.attn.q_proj.weight\n",
      "model.transformer.h.0.attn.out_proj.weight\n",
      "model.transformer.h.0.mlp.fc_in.weight\n",
      "model.transformer.h.0.mlp.fc_in.bias\n",
      "model.transformer.h.0.mlp.fc_out.weight\n",
      "model.transformer.h.0.mlp.fc_out.bias\n",
      "model.transformer.h.1.ln_1.weight\n",
      "model.transformer.h.1.ln_1.bias\n",
      "model.transformer.h.1.attn.bias\n",
      "model.transformer.h.1.attn.masked_bias\n",
      "model.transformer.h.1.attn.k_proj.weight\n",
      "model.transformer.h.1.attn.v_proj.weight\n",
      "model.transformer.h.1.attn.q_proj.weight\n",
      "model.transformer.h.1.attn.out_proj.weight\n",
      "model.transformer.h.1.mlp.fc_in.weight\n",
      "model.transformer.h.1.mlp.fc_in.bias\n",
      "model.transformer.h.1.mlp.fc_out.weight\n",
      "model.transformer.h.1.mlp.fc_out.bias\n",
      "model.transformer.h.2.ln_1.weight\n",
      "model.transformer.h.2.ln_1.bias\n",
      "model.transformer.h.2.attn.bias\n",
      "model.transformer.h.2.attn.masked_bias\n",
      "model.transformer.h.2.attn.k_proj.weight\n",
      "model.transformer.h.2.attn.v_proj.weight\n",
      "model.transformer.h.2.attn.q_proj.weight\n",
      "model.transformer.h.2.attn.out_proj.weight\n",
      "model.transformer.h.2.mlp.fc_in.weight\n",
      "model.transformer.h.2.mlp.fc_in.bias\n",
      "model.transformer.h.2.mlp.fc_out.weight\n",
      "model.transformer.h.2.mlp.fc_out.bias\n",
      "model.transformer.h.3.ln_1.weight\n",
      "model.transformer.h.3.ln_1.bias\n",
      "model.transformer.h.3.attn.bias\n",
      "model.transformer.h.3.attn.masked_bias\n",
      "model.transformer.h.3.attn.k_proj.weight\n",
      "model.transformer.h.3.attn.v_proj.weight\n",
      "model.transformer.h.3.attn.q_proj.weight\n",
      "model.transformer.h.3.attn.out_proj.weight\n",
      "model.transformer.h.3.mlp.fc_in.weight\n",
      "model.transformer.h.3.mlp.fc_in.bias\n",
      "model.transformer.h.3.mlp.fc_out.weight\n",
      "model.transformer.h.3.mlp.fc_out.bias\n",
      "model.transformer.h.4.ln_1.weight\n",
      "model.transformer.h.4.ln_1.bias\n",
      "model.transformer.h.4.attn.bias\n",
      "model.transformer.h.4.attn.masked_bias\n",
      "model.transformer.h.4.attn.k_proj.weight\n",
      "model.transformer.h.4.attn.v_proj.weight\n",
      "model.transformer.h.4.attn.q_proj.weight\n",
      "model.transformer.h.4.attn.out_proj.weight\n",
      "model.transformer.h.4.mlp.fc_in.weight\n",
      "model.transformer.h.4.mlp.fc_in.bias\n",
      "model.transformer.h.4.mlp.fc_out.weight\n",
      "model.transformer.h.4.mlp.fc_out.bias\n",
      "model.transformer.h.5.ln_1.weight\n",
      "model.transformer.h.5.ln_1.bias\n",
      "model.transformer.h.5.attn.bias\n",
      "model.transformer.h.5.attn.masked_bias\n",
      "model.transformer.h.5.attn.k_proj.weight\n",
      "model.transformer.h.5.attn.v_proj.weight\n",
      "model.transformer.h.5.attn.q_proj.weight\n",
      "model.transformer.h.5.attn.out_proj.weight\n",
      "model.transformer.h.5.mlp.fc_in.weight\n",
      "model.transformer.h.5.mlp.fc_in.bias\n",
      "model.transformer.h.5.mlp.fc_out.weight\n",
      "model.transformer.h.5.mlp.fc_out.bias\n",
      "model.transformer.h.6.ln_1.weight\n",
      "model.transformer.h.6.ln_1.bias\n",
      "model.transformer.h.6.attn.bias\n",
      "model.transformer.h.6.attn.masked_bias\n",
      "model.transformer.h.6.attn.k_proj.weight\n",
      "model.transformer.h.6.attn.v_proj.weight\n",
      "model.transformer.h.6.attn.q_proj.weight\n",
      "model.transformer.h.6.attn.out_proj.weight\n",
      "model.transformer.h.6.mlp.fc_in.weight\n",
      "model.transformer.h.6.mlp.fc_in.bias\n",
      "model.transformer.h.6.mlp.fc_out.weight\n",
      "model.transformer.h.6.mlp.fc_out.bias\n",
      "model.transformer.h.7.ln_1.weight\n",
      "model.transformer.h.7.ln_1.bias\n",
      "model.transformer.h.7.attn.bias\n",
      "model.transformer.h.7.attn.masked_bias\n",
      "model.transformer.h.7.attn.k_proj.weight\n",
      "model.transformer.h.7.attn.v_proj.weight\n",
      "model.transformer.h.7.attn.q_proj.weight\n",
      "model.transformer.h.7.attn.out_proj.weight\n",
      "model.transformer.h.7.mlp.fc_in.weight\n",
      "model.transformer.h.7.mlp.fc_in.bias\n",
      "model.transformer.h.7.mlp.fc_out.weight\n",
      "model.transformer.h.7.mlp.fc_out.bias\n",
      "model.transformer.h.8.ln_1.weight\n",
      "model.transformer.h.8.ln_1.bias\n",
      "model.transformer.h.8.attn.bias\n",
      "model.transformer.h.8.attn.masked_bias\n",
      "model.transformer.h.8.attn.k_proj.weight\n",
      "model.transformer.h.8.attn.v_proj.weight\n",
      "model.transformer.h.8.attn.q_proj.weight\n",
      "model.transformer.h.8.attn.out_proj.weight\n",
      "model.transformer.h.8.mlp.fc_in.weight\n",
      "model.transformer.h.8.mlp.fc_in.bias\n",
      "model.transformer.h.8.mlp.fc_out.weight\n",
      "model.transformer.h.8.mlp.fc_out.bias\n",
      "model.transformer.h.9.ln_1.weight\n",
      "model.transformer.h.9.ln_1.bias\n",
      "model.transformer.h.9.attn.bias\n",
      "model.transformer.h.9.attn.masked_bias\n",
      "model.transformer.h.9.attn.k_proj.weight\n",
      "model.transformer.h.9.attn.v_proj.weight\n",
      "model.transformer.h.9.attn.q_proj.weight\n",
      "model.transformer.h.9.attn.out_proj.weight\n",
      "model.transformer.h.9.mlp.fc_in.weight\n",
      "model.transformer.h.9.mlp.fc_in.bias\n",
      "model.transformer.h.9.mlp.fc_out.weight\n",
      "model.transformer.h.9.mlp.fc_out.bias\n",
      "model.transformer.h.10.ln_1.weight\n",
      "model.transformer.h.10.ln_1.bias\n",
      "model.transformer.h.10.attn.bias\n",
      "model.transformer.h.10.attn.masked_bias\n",
      "model.transformer.h.10.attn.k_proj.weight\n",
      "model.transformer.h.10.attn.v_proj.weight\n",
      "model.transformer.h.10.attn.q_proj.weight\n",
      "model.transformer.h.10.attn.out_proj.weight\n",
      "model.transformer.h.10.mlp.fc_in.weight\n",
      "model.transformer.h.10.mlp.fc_in.bias\n",
      "model.transformer.h.10.mlp.fc_out.weight\n",
      "model.transformer.h.10.mlp.fc_out.bias\n",
      "model.transformer.h.11.ln_1.weight\n",
      "model.transformer.h.11.ln_1.bias\n",
      "model.transformer.h.11.attn.bias\n",
      "model.transformer.h.11.attn.masked_bias\n",
      "model.transformer.h.11.attn.k_proj.weight\n",
      "model.transformer.h.11.attn.v_proj.weight\n",
      "model.transformer.h.11.attn.q_proj.weight\n",
      "model.transformer.h.11.attn.out_proj.weight\n",
      "model.transformer.h.11.mlp.fc_in.weight\n",
      "model.transformer.h.11.mlp.fc_in.bias\n",
      "model.transformer.h.11.mlp.fc_out.weight\n",
      "model.transformer.h.11.mlp.fc_out.bias\n",
      "model.transformer.h.12.ln_1.weight\n",
      "model.transformer.h.12.ln_1.bias\n",
      "model.transformer.h.12.attn.bias\n",
      "model.transformer.h.12.attn.masked_bias\n",
      "model.transformer.h.12.attn.k_proj.weight\n",
      "model.transformer.h.12.attn.v_proj.weight\n",
      "model.transformer.h.12.attn.q_proj.weight\n",
      "model.transformer.h.12.attn.out_proj.weight\n",
      "model.transformer.h.12.mlp.fc_in.weight\n",
      "model.transformer.h.12.mlp.fc_in.bias\n",
      "model.transformer.h.12.mlp.fc_out.weight\n",
      "model.transformer.h.12.mlp.fc_out.bias\n",
      "model.transformer.h.13.ln_1.weight\n",
      "model.transformer.h.13.ln_1.bias\n",
      "model.transformer.h.13.attn.bias\n",
      "model.transformer.h.13.attn.masked_bias\n",
      "model.transformer.h.13.attn.k_proj.weight\n",
      "model.transformer.h.13.attn.v_proj.weight\n",
      "model.transformer.h.13.attn.q_proj.weight\n",
      "model.transformer.h.13.attn.out_proj.weight\n",
      "model.transformer.h.13.mlp.fc_in.weight\n",
      "model.transformer.h.13.mlp.fc_in.bias\n",
      "model.transformer.h.13.mlp.fc_out.weight\n",
      "model.transformer.h.13.mlp.fc_out.bias\n",
      "model.transformer.h.14.ln_1.weight\n",
      "model.transformer.h.14.ln_1.bias\n",
      "model.transformer.h.14.attn.bias\n",
      "model.transformer.h.14.attn.masked_bias\n",
      "model.transformer.h.14.attn.k_proj.weight\n",
      "model.transformer.h.14.attn.v_proj.weight\n",
      "model.transformer.h.14.attn.q_proj.weight\n",
      "model.transformer.h.14.attn.out_proj.weight\n",
      "model.transformer.h.14.mlp.fc_in.weight\n",
      "model.transformer.h.14.mlp.fc_in.bias\n",
      "model.transformer.h.14.mlp.fc_out.weight\n",
      "model.transformer.h.14.mlp.fc_out.bias\n",
      "model.transformer.h.15.ln_1.weight\n",
      "model.transformer.h.15.ln_1.bias\n",
      "model.transformer.h.15.attn.bias\n",
      "model.transformer.h.15.attn.masked_bias\n",
      "model.transformer.h.15.attn.k_proj.weight\n",
      "model.transformer.h.15.attn.v_proj.weight\n",
      "model.transformer.h.15.attn.q_proj.weight\n",
      "model.transformer.h.15.attn.out_proj.weight\n",
      "model.transformer.h.15.mlp.fc_in.weight\n",
      "model.transformer.h.15.mlp.fc_in.bias\n",
      "model.transformer.h.15.mlp.fc_out.weight\n",
      "model.transformer.h.15.mlp.fc_out.bias\n",
      "model.transformer.h.16.ln_1.weight\n",
      "model.transformer.h.16.ln_1.bias\n",
      "model.transformer.h.16.attn.bias\n",
      "model.transformer.h.16.attn.masked_bias\n",
      "model.transformer.h.16.attn.k_proj.weight\n",
      "model.transformer.h.16.attn.v_proj.weight\n",
      "model.transformer.h.16.attn.q_proj.weight\n",
      "model.transformer.h.16.attn.out_proj.weight\n",
      "model.transformer.h.16.mlp.fc_in.weight\n",
      "model.transformer.h.16.mlp.fc_in.bias\n",
      "model.transformer.h.16.mlp.fc_out.weight\n",
      "model.transformer.h.16.mlp.fc_out.bias\n",
      "model.transformer.h.17.ln_1.weight\n",
      "model.transformer.h.17.ln_1.bias\n",
      "model.transformer.h.17.attn.bias\n",
      "model.transformer.h.17.attn.masked_bias\n",
      "model.transformer.h.17.attn.k_proj.weight\n",
      "model.transformer.h.17.attn.v_proj.weight\n",
      "model.transformer.h.17.attn.q_proj.weight\n",
      "model.transformer.h.17.attn.out_proj.weight\n",
      "model.transformer.h.17.mlp.fc_in.weight\n",
      "model.transformer.h.17.mlp.fc_in.bias\n",
      "model.transformer.h.17.mlp.fc_out.weight\n",
      "model.transformer.h.17.mlp.fc_out.bias\n",
      "model.transformer.h.18.ln_1.weight\n",
      "model.transformer.h.18.ln_1.bias\n",
      "model.transformer.h.18.attn.bias\n",
      "model.transformer.h.18.attn.masked_bias\n",
      "model.transformer.h.18.attn.k_proj.weight\n",
      "model.transformer.h.18.attn.v_proj.weight\n",
      "model.transformer.h.18.attn.q_proj.weight\n",
      "model.transformer.h.18.attn.out_proj.weight\n",
      "model.transformer.h.18.mlp.fc_in.weight\n",
      "model.transformer.h.18.mlp.fc_in.bias\n",
      "model.transformer.h.18.mlp.fc_out.weight\n",
      "model.transformer.h.18.mlp.fc_out.bias\n",
      "model.transformer.h.19.ln_1.weight\n",
      "model.transformer.h.19.ln_1.bias\n",
      "model.transformer.h.19.attn.bias\n",
      "model.transformer.h.19.attn.masked_bias\n",
      "model.transformer.h.19.attn.k_proj.weight\n",
      "model.transformer.h.19.attn.v_proj.weight\n",
      "model.transformer.h.19.attn.q_proj.weight\n",
      "model.transformer.h.19.attn.out_proj.weight\n",
      "model.transformer.h.19.mlp.fc_in.weight\n",
      "model.transformer.h.19.mlp.fc_in.bias\n",
      "model.transformer.h.19.mlp.fc_out.weight\n",
      "model.transformer.h.19.mlp.fc_out.bias\n",
      "model.transformer.h.20.ln_1.weight\n",
      "model.transformer.h.20.ln_1.bias\n",
      "model.transformer.h.20.attn.bias\n",
      "model.transformer.h.20.attn.masked_bias\n",
      "model.transformer.h.20.attn.k_proj.weight\n",
      "model.transformer.h.20.attn.v_proj.weight\n",
      "model.transformer.h.20.attn.q_proj.weight\n",
      "model.transformer.h.20.attn.out_proj.weight\n",
      "model.transformer.h.20.mlp.fc_in.weight\n",
      "model.transformer.h.20.mlp.fc_in.bias\n",
      "model.transformer.h.20.mlp.fc_out.weight\n",
      "model.transformer.h.20.mlp.fc_out.bias\n",
      "model.transformer.h.21.ln_1.weight\n",
      "model.transformer.h.21.ln_1.bias\n",
      "model.transformer.h.21.attn.bias\n",
      "model.transformer.h.21.attn.masked_bias\n",
      "model.transformer.h.21.attn.k_proj.weight\n",
      "model.transformer.h.21.attn.v_proj.weight\n",
      "model.transformer.h.21.attn.q_proj.weight\n",
      "model.transformer.h.21.attn.out_proj.weight\n",
      "model.transformer.h.21.mlp.fc_in.weight\n",
      "model.transformer.h.21.mlp.fc_in.bias\n",
      "model.transformer.h.21.mlp.fc_out.weight\n",
      "model.transformer.h.21.mlp.fc_out.bias\n",
      "model.transformer.h.22.ln_1.weight\n",
      "model.transformer.h.22.ln_1.bias\n",
      "model.transformer.h.22.attn.bias\n",
      "model.transformer.h.22.attn.masked_bias\n",
      "model.transformer.h.22.attn.k_proj.weight\n",
      "model.transformer.h.22.attn.v_proj.weight\n",
      "model.transformer.h.22.attn.q_proj.weight\n",
      "model.transformer.h.22.attn.out_proj.weight\n",
      "model.transformer.h.22.mlp.fc_in.weight\n",
      "model.transformer.h.22.mlp.fc_in.bias\n",
      "model.transformer.h.22.mlp.fc_out.weight\n",
      "model.transformer.h.22.mlp.fc_out.bias\n",
      "model.transformer.h.23.ln_1.weight\n",
      "model.transformer.h.23.ln_1.bias\n",
      "model.transformer.h.23.attn.bias\n",
      "model.transformer.h.23.attn.masked_bias\n",
      "model.transformer.h.23.attn.k_proj.weight\n",
      "model.transformer.h.23.attn.v_proj.weight\n",
      "model.transformer.h.23.attn.q_proj.weight\n",
      "model.transformer.h.23.attn.out_proj.weight\n",
      "model.transformer.h.23.mlp.fc_in.weight\n",
      "model.transformer.h.23.mlp.fc_in.bias\n",
      "model.transformer.h.23.mlp.fc_out.weight\n",
      "model.transformer.h.23.mlp.fc_out.bias\n",
      "model.transformer.h.24.ln_1.weight\n",
      "model.transformer.h.24.ln_1.bias\n",
      "model.transformer.h.24.attn.bias\n",
      "model.transformer.h.24.attn.masked_bias\n",
      "model.transformer.h.24.attn.k_proj.weight\n",
      "model.transformer.h.24.attn.v_proj.weight\n",
      "model.transformer.h.24.attn.q_proj.weight\n",
      "model.transformer.h.24.attn.out_proj.weight\n",
      "model.transformer.h.24.mlp.fc_in.weight\n",
      "model.transformer.h.24.mlp.fc_in.bias\n",
      "model.transformer.h.24.mlp.fc_out.weight\n",
      "model.transformer.h.24.mlp.fc_out.bias\n",
      "model.transformer.h.25.ln_1.weight\n",
      "model.transformer.h.25.ln_1.bias\n",
      "model.transformer.h.25.attn.bias\n",
      "model.transformer.h.25.attn.masked_bias\n",
      "model.transformer.h.25.attn.k_proj.weight\n",
      "model.transformer.h.25.attn.v_proj.weight\n",
      "model.transformer.h.25.attn.q_proj.weight\n",
      "model.transformer.h.25.attn.out_proj.weight\n",
      "model.transformer.h.25.mlp.fc_in.weight\n",
      "model.transformer.h.25.mlp.fc_in.bias\n",
      "model.transformer.h.25.mlp.fc_out.weight\n",
      "model.transformer.h.25.mlp.fc_out.bias\n",
      "model.transformer.h.26.ln_1.weight\n",
      "model.transformer.h.26.ln_1.bias\n",
      "model.transformer.h.26.attn.bias\n",
      "model.transformer.h.26.attn.masked_bias\n",
      "model.transformer.h.26.attn.k_proj.weight\n",
      "model.transformer.h.26.attn.v_proj.weight\n",
      "model.transformer.h.26.attn.q_proj.weight\n",
      "model.transformer.h.26.attn.out_proj.weight\n",
      "model.transformer.h.26.mlp.fc_in.weight\n",
      "model.transformer.h.26.mlp.fc_in.bias\n",
      "model.transformer.h.26.mlp.fc_out.weight\n",
      "model.transformer.h.26.mlp.fc_out.bias\n",
      "model.transformer.h.27.ln_1.weight\n",
      "model.transformer.h.27.ln_1.bias\n",
      "model.transformer.h.27.attn.bias\n",
      "model.transformer.h.27.attn.masked_bias\n",
      "model.transformer.h.27.attn.k_proj.weight\n",
      "model.transformer.h.27.attn.v_proj.weight\n",
      "model.transformer.h.27.attn.q_proj.weight\n",
      "model.transformer.h.27.attn.out_proj.weight\n",
      "model.transformer.h.27.mlp.fc_in.weight\n",
      "model.transformer.h.27.mlp.fc_in.bias\n",
      "model.transformer.h.27.mlp.fc_out.weight\n",
      "model.transformer.h.27.mlp.fc_out.bias\n",
      "model.transformer.ln_f.weight\n",
      "model.transformer.ln_f.bias\n",
      "model.lm_head.weight\n",
      "model.lm_head.bias\n",
      "transformer.wte.weight\n",
      "transformer.h.0.ln_1.weight\n",
      "transformer.h.0.ln_1.bias\n",
      "transformer.h.0.attn.bias\n",
      "transformer.h.0.attn.masked_bias\n",
      "transformer.h.0.attn.k_proj.weight\n",
      "transformer.h.0.attn.v_proj.weight\n",
      "transformer.h.0.attn.q_proj.weight\n",
      "transformer.h.0.attn.out_proj.weight\n",
      "transformer.h.0.mlp.fc_in.weight\n",
      "transformer.h.0.mlp.fc_in.bias\n",
      "transformer.h.0.mlp.fc_out.weight\n",
      "transformer.h.0.mlp.fc_out.bias\n",
      "transformer.h.1.ln_1.weight\n",
      "transformer.h.1.ln_1.bias\n",
      "transformer.h.1.attn.bias\n",
      "transformer.h.1.attn.masked_bias\n",
      "transformer.h.1.attn.k_proj.weight\n",
      "transformer.h.1.attn.v_proj.weight\n",
      "transformer.h.1.attn.q_proj.weight\n",
      "transformer.h.1.attn.out_proj.weight\n",
      "transformer.h.1.mlp.fc_in.weight\n",
      "transformer.h.1.mlp.fc_in.bias\n",
      "transformer.h.1.mlp.fc_out.weight\n",
      "transformer.h.1.mlp.fc_out.bias\n",
      "transformer.h.2.ln_1.weight\n",
      "transformer.h.2.ln_1.bias\n",
      "transformer.h.2.attn.bias\n",
      "transformer.h.2.attn.masked_bias\n",
      "transformer.h.2.attn.k_proj.weight\n",
      "transformer.h.2.attn.v_proj.weight\n",
      "transformer.h.2.attn.q_proj.weight\n",
      "transformer.h.2.attn.out_proj.weight\n",
      "transformer.h.2.mlp.fc_in.weight\n",
      "transformer.h.2.mlp.fc_in.bias\n",
      "transformer.h.2.mlp.fc_out.weight\n",
      "transformer.h.2.mlp.fc_out.bias\n",
      "transformer.h.3.ln_1.weight\n",
      "transformer.h.3.ln_1.bias\n",
      "transformer.h.3.attn.bias\n",
      "transformer.h.3.attn.masked_bias\n",
      "transformer.h.3.attn.k_proj.weight\n",
      "transformer.h.3.attn.v_proj.weight\n",
      "transformer.h.3.attn.q_proj.weight\n",
      "transformer.h.3.attn.out_proj.weight\n",
      "transformer.h.3.mlp.fc_in.weight\n",
      "transformer.h.3.mlp.fc_in.bias\n",
      "transformer.h.3.mlp.fc_out.weight\n",
      "transformer.h.3.mlp.fc_out.bias\n",
      "transformer.h.4.ln_1.weight\n",
      "transformer.h.4.ln_1.bias\n",
      "transformer.h.4.attn.bias\n",
      "transformer.h.4.attn.masked_bias\n",
      "transformer.h.4.attn.k_proj.weight\n",
      "transformer.h.4.attn.v_proj.weight\n",
      "transformer.h.4.attn.q_proj.weight\n",
      "transformer.h.4.attn.out_proj.weight\n",
      "transformer.h.4.mlp.fc_in.weight\n",
      "transformer.h.4.mlp.fc_in.bias\n",
      "transformer.h.4.mlp.fc_out.weight\n",
      "transformer.h.4.mlp.fc_out.bias\n",
      "transformer.h.5.ln_1.weight\n",
      "transformer.h.5.ln_1.bias\n",
      "transformer.h.5.attn.bias\n",
      "transformer.h.5.attn.masked_bias\n",
      "transformer.h.5.attn.k_proj.weight\n",
      "transformer.h.5.attn.v_proj.weight\n",
      "transformer.h.5.attn.q_proj.weight\n",
      "transformer.h.5.attn.out_proj.weight\n",
      "transformer.h.5.mlp.fc_in.weight\n",
      "transformer.h.5.mlp.fc_in.bias\n",
      "transformer.h.5.mlp.fc_out.weight\n",
      "transformer.h.5.mlp.fc_out.bias\n",
      "transformer.h.6.ln_1.weight\n",
      "transformer.h.6.ln_1.bias\n",
      "transformer.h.6.attn.bias\n",
      "transformer.h.6.attn.masked_bias\n",
      "transformer.h.6.attn.k_proj.weight\n",
      "transformer.h.6.attn.v_proj.weight\n",
      "transformer.h.6.attn.q_proj.weight\n",
      "transformer.h.6.attn.out_proj.weight\n",
      "transformer.h.6.mlp.fc_in.weight\n",
      "transformer.h.6.mlp.fc_in.bias\n",
      "transformer.h.6.mlp.fc_out.weight\n",
      "transformer.h.6.mlp.fc_out.bias\n",
      "transformer.h.7.ln_1.weight\n",
      "transformer.h.7.ln_1.bias\n",
      "transformer.h.7.attn.bias\n",
      "transformer.h.7.attn.masked_bias\n",
      "transformer.h.7.attn.k_proj.weight\n",
      "transformer.h.7.attn.v_proj.weight\n",
      "transformer.h.7.attn.q_proj.weight\n",
      "transformer.h.7.attn.out_proj.weight\n",
      "transformer.h.7.mlp.fc_in.weight\n",
      "transformer.h.7.mlp.fc_in.bias\n",
      "transformer.h.7.mlp.fc_out.weight\n",
      "transformer.h.7.mlp.fc_out.bias\n",
      "transformer.h.8.ln_1.weight\n",
      "transformer.h.8.ln_1.bias\n",
      "transformer.h.8.attn.bias\n",
      "transformer.h.8.attn.masked_bias\n",
      "transformer.h.8.attn.k_proj.weight\n",
      "transformer.h.8.attn.v_proj.weight\n",
      "transformer.h.8.attn.q_proj.weight\n",
      "transformer.h.8.attn.out_proj.weight\n",
      "transformer.h.8.mlp.fc_in.weight\n",
      "transformer.h.8.mlp.fc_in.bias\n",
      "transformer.h.8.mlp.fc_out.weight\n",
      "transformer.h.8.mlp.fc_out.bias\n",
      "transformer.h.9.ln_1.weight\n",
      "transformer.h.9.ln_1.bias\n",
      "transformer.h.9.attn.bias\n",
      "transformer.h.9.attn.masked_bias\n",
      "transformer.h.9.attn.k_proj.weight\n",
      "transformer.h.9.attn.v_proj.weight\n",
      "transformer.h.9.attn.q_proj.weight\n",
      "transformer.h.9.attn.out_proj.weight\n",
      "transformer.h.9.mlp.fc_in.weight\n",
      "transformer.h.9.mlp.fc_in.bias\n",
      "transformer.h.9.mlp.fc_out.weight\n",
      "transformer.h.9.mlp.fc_out.bias\n",
      "transformer.h.10.ln_1.weight\n",
      "transformer.h.10.ln_1.bias\n",
      "transformer.h.10.attn.bias\n",
      "transformer.h.10.attn.masked_bias\n",
      "transformer.h.10.attn.k_proj.weight\n",
      "transformer.h.10.attn.v_proj.weight\n",
      "transformer.h.10.attn.q_proj.weight\n",
      "transformer.h.10.attn.out_proj.weight\n",
      "transformer.h.10.mlp.fc_in.weight\n",
      "transformer.h.10.mlp.fc_in.bias\n",
      "transformer.h.10.mlp.fc_out.weight\n",
      "transformer.h.10.mlp.fc_out.bias\n",
      "transformer.h.11.ln_1.weight\n",
      "transformer.h.11.ln_1.bias\n",
      "transformer.h.11.attn.bias\n",
      "transformer.h.11.attn.masked_bias\n",
      "transformer.h.11.attn.k_proj.weight\n",
      "transformer.h.11.attn.v_proj.weight\n",
      "transformer.h.11.attn.q_proj.weight\n",
      "transformer.h.11.attn.out_proj.weight\n",
      "transformer.h.11.mlp.fc_in.weight\n",
      "transformer.h.11.mlp.fc_in.bias\n",
      "transformer.h.11.mlp.fc_out.weight\n",
      "transformer.h.11.mlp.fc_out.bias\n",
      "transformer.h.12.ln_1.weight\n",
      "transformer.h.12.ln_1.bias\n",
      "transformer.h.12.attn.bias\n",
      "transformer.h.12.attn.masked_bias\n",
      "transformer.h.12.attn.k_proj.weight\n",
      "transformer.h.12.attn.v_proj.weight\n",
      "transformer.h.12.attn.q_proj.weight\n",
      "transformer.h.12.attn.out_proj.weight\n",
      "transformer.h.12.mlp.fc_in.weight\n",
      "transformer.h.12.mlp.fc_in.bias\n",
      "transformer.h.12.mlp.fc_out.weight\n",
      "transformer.h.12.mlp.fc_out.bias\n",
      "transformer.h.13.ln_1.weight\n",
      "transformer.h.13.ln_1.bias\n",
      "transformer.h.13.attn.bias\n",
      "transformer.h.13.attn.masked_bias\n",
      "transformer.h.13.attn.k_proj.weight\n",
      "transformer.h.13.attn.v_proj.weight\n",
      "transformer.h.13.attn.q_proj.weight\n",
      "transformer.h.13.attn.out_proj.weight\n",
      "transformer.h.13.mlp.fc_in.weight\n",
      "transformer.h.13.mlp.fc_in.bias\n",
      "transformer.h.13.mlp.fc_out.weight\n",
      "transformer.h.13.mlp.fc_out.bias\n",
      "transformer.h.14.ln_1.weight\n",
      "transformer.h.14.ln_1.bias\n",
      "transformer.h.14.attn.bias\n",
      "transformer.h.14.attn.masked_bias\n",
      "transformer.h.14.attn.k_proj.weight\n",
      "transformer.h.14.attn.v_proj.weight\n",
      "transformer.h.14.attn.q_proj.weight\n",
      "transformer.h.14.attn.out_proj.weight\n",
      "transformer.h.14.mlp.fc_in.weight\n",
      "transformer.h.14.mlp.fc_in.bias\n",
      "transformer.h.14.mlp.fc_out.weight\n",
      "transformer.h.14.mlp.fc_out.bias\n",
      "transformer.h.15.ln_1.weight\n",
      "transformer.h.15.ln_1.bias\n",
      "transformer.h.15.attn.bias\n",
      "transformer.h.15.attn.masked_bias\n",
      "transformer.h.15.attn.k_proj.weight\n",
      "transformer.h.15.attn.v_proj.weight\n",
      "transformer.h.15.attn.q_proj.weight\n",
      "transformer.h.15.attn.out_proj.weight\n",
      "transformer.h.15.mlp.fc_in.weight\n",
      "transformer.h.15.mlp.fc_in.bias\n",
      "transformer.h.15.mlp.fc_out.weight\n",
      "transformer.h.15.mlp.fc_out.bias\n",
      "transformer.h.16.ln_1.weight\n",
      "transformer.h.16.ln_1.bias\n",
      "transformer.h.16.attn.bias\n",
      "transformer.h.16.attn.masked_bias\n",
      "transformer.h.16.attn.k_proj.weight\n",
      "transformer.h.16.attn.v_proj.weight\n",
      "transformer.h.16.attn.q_proj.weight\n",
      "transformer.h.16.attn.out_proj.weight\n",
      "transformer.h.16.mlp.fc_in.weight\n",
      "transformer.h.16.mlp.fc_in.bias\n",
      "transformer.h.16.mlp.fc_out.weight\n",
      "transformer.h.16.mlp.fc_out.bias\n",
      "transformer.h.17.ln_1.weight\n",
      "transformer.h.17.ln_1.bias\n",
      "transformer.h.17.attn.bias\n",
      "transformer.h.17.attn.masked_bias\n",
      "transformer.h.17.attn.k_proj.weight\n",
      "transformer.h.17.attn.v_proj.weight\n",
      "transformer.h.17.attn.q_proj.weight\n",
      "transformer.h.17.attn.out_proj.weight\n",
      "transformer.h.17.mlp.fc_in.weight\n",
      "transformer.h.17.mlp.fc_in.bias\n",
      "transformer.h.17.mlp.fc_out.weight\n",
      "transformer.h.17.mlp.fc_out.bias\n",
      "transformer.h.18.ln_1.weight\n",
      "transformer.h.18.ln_1.bias\n",
      "transformer.h.18.attn.bias\n",
      "transformer.h.18.attn.masked_bias\n",
      "transformer.h.18.attn.k_proj.weight\n",
      "transformer.h.18.attn.v_proj.weight\n",
      "transformer.h.18.attn.q_proj.weight\n",
      "transformer.h.18.attn.out_proj.weight\n",
      "transformer.h.18.mlp.fc_in.weight\n",
      "transformer.h.18.mlp.fc_in.bias\n",
      "transformer.h.18.mlp.fc_out.weight\n",
      "transformer.h.18.mlp.fc_out.bias\n",
      "transformer.h.19.ln_1.weight\n",
      "transformer.h.19.ln_1.bias\n",
      "transformer.h.19.attn.bias\n",
      "transformer.h.19.attn.masked_bias\n",
      "transformer.h.19.attn.k_proj.weight\n",
      "transformer.h.19.attn.v_proj.weight\n",
      "transformer.h.19.attn.q_proj.weight\n",
      "transformer.h.19.attn.out_proj.weight\n",
      "transformer.h.19.mlp.fc_in.weight\n",
      "transformer.h.19.mlp.fc_in.bias\n",
      "transformer.h.19.mlp.fc_out.weight\n",
      "transformer.h.19.mlp.fc_out.bias\n",
      "transformer.h.20.ln_1.weight\n",
      "transformer.h.20.ln_1.bias\n",
      "transformer.h.20.attn.bias\n",
      "transformer.h.20.attn.masked_bias\n",
      "transformer.h.20.attn.k_proj.weight\n",
      "transformer.h.20.attn.v_proj.weight\n",
      "transformer.h.20.attn.q_proj.weight\n",
      "transformer.h.20.attn.out_proj.weight\n",
      "transformer.h.20.mlp.fc_in.weight\n",
      "transformer.h.20.mlp.fc_in.bias\n",
      "transformer.h.20.mlp.fc_out.weight\n",
      "transformer.h.20.mlp.fc_out.bias\n",
      "transformer.h.21.ln_1.weight\n",
      "transformer.h.21.ln_1.bias\n",
      "transformer.h.21.attn.bias\n",
      "transformer.h.21.attn.masked_bias\n",
      "transformer.h.21.attn.k_proj.weight\n",
      "transformer.h.21.attn.v_proj.weight\n",
      "transformer.h.21.attn.q_proj.weight\n",
      "transformer.h.21.attn.out_proj.weight\n",
      "transformer.h.21.mlp.fc_in.weight\n",
      "transformer.h.21.mlp.fc_in.bias\n",
      "transformer.h.21.mlp.fc_out.weight\n",
      "transformer.h.21.mlp.fc_out.bias\n",
      "transformer.h.22.ln_1.weight\n",
      "transformer.h.22.ln_1.bias\n",
      "transformer.h.22.attn.bias\n",
      "transformer.h.22.attn.masked_bias\n",
      "transformer.h.22.attn.k_proj.weight\n",
      "transformer.h.22.attn.v_proj.weight\n",
      "transformer.h.22.attn.q_proj.weight\n",
      "transformer.h.22.attn.out_proj.weight\n",
      "transformer.h.22.mlp.fc_in.weight\n",
      "transformer.h.22.mlp.fc_in.bias\n",
      "transformer.h.22.mlp.fc_out.weight\n",
      "transformer.h.22.mlp.fc_out.bias\n",
      "transformer.h.23.ln_1.weight\n",
      "transformer.h.23.ln_1.bias\n",
      "transformer.h.23.attn.bias\n",
      "transformer.h.23.attn.masked_bias\n",
      "transformer.h.23.attn.k_proj.weight\n",
      "transformer.h.23.attn.v_proj.weight\n",
      "transformer.h.23.attn.q_proj.weight\n",
      "transformer.h.23.attn.out_proj.weight\n",
      "transformer.h.23.mlp.fc_in.weight\n",
      "transformer.h.23.mlp.fc_in.bias\n",
      "transformer.h.23.mlp.fc_out.weight\n",
      "transformer.h.23.mlp.fc_out.bias\n",
      "transformer.h.24.ln_1.weight\n",
      "transformer.h.24.ln_1.bias\n",
      "transformer.h.24.attn.bias\n",
      "transformer.h.24.attn.masked_bias\n",
      "transformer.h.24.attn.k_proj.weight\n",
      "transformer.h.24.attn.v_proj.weight\n",
      "transformer.h.24.attn.q_proj.weight\n",
      "transformer.h.24.attn.out_proj.weight\n",
      "transformer.h.24.mlp.fc_in.weight\n",
      "transformer.h.24.mlp.fc_in.bias\n",
      "transformer.h.24.mlp.fc_out.weight\n",
      "transformer.h.24.mlp.fc_out.bias\n",
      "transformer.h.25.ln_1.weight\n",
      "transformer.h.25.ln_1.bias\n",
      "transformer.h.25.attn.bias\n",
      "transformer.h.25.attn.masked_bias\n",
      "transformer.h.25.attn.k_proj.weight\n",
      "transformer.h.25.attn.v_proj.weight\n",
      "transformer.h.25.attn.q_proj.weight\n",
      "transformer.h.25.attn.out_proj.weight\n",
      "transformer.h.25.mlp.fc_in.weight\n",
      "transformer.h.25.mlp.fc_in.bias\n",
      "transformer.h.25.mlp.fc_out.weight\n",
      "transformer.h.25.mlp.fc_out.bias\n",
      "transformer.h.26.ln_1.weight\n",
      "transformer.h.26.ln_1.bias\n",
      "transformer.h.26.attn.bias\n",
      "transformer.h.26.attn.masked_bias\n",
      "transformer.h.26.attn.k_proj.weight\n",
      "transformer.h.26.attn.v_proj.weight\n",
      "transformer.h.26.attn.q_proj.weight\n",
      "transformer.h.26.attn.out_proj.weight\n",
      "transformer.h.26.mlp.fc_in.weight\n",
      "transformer.h.26.mlp.fc_in.bias\n",
      "transformer.h.26.mlp.fc_out.weight\n",
      "transformer.h.26.mlp.fc_out.bias\n",
      "transformer.h.27.ln_1.weight\n",
      "transformer.h.27.ln_1.bias\n",
      "transformer.h.27.attn.bias\n",
      "transformer.h.27.attn.masked_bias\n",
      "transformer.h.27.attn.k_proj.weight\n",
      "transformer.h.27.attn.v_proj.weight\n",
      "transformer.h.27.attn.q_proj.weight\n",
      "transformer.h.27.attn.out_proj.weight\n",
      "transformer.h.27.mlp.fc_in.weight\n",
      "transformer.h.27.mlp.fc_in.bias\n",
      "transformer.h.27.mlp.fc_out.weight\n",
      "transformer.h.27.mlp.fc_out.bias\n",
      "transformer.ln_f.weight\n",
      "transformer.ln_f.bias\n",
      "v_head.weight\n"
     ]
    }
   ],
   "source": [
    "for key in gptj_rm_state.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b8cbcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2674f614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer.h.0.attn.bias\n",
      "transformer.h.0.attn.masked_bias\n",
      "transformer.h.1.attn.bias\n",
      "transformer.h.1.attn.masked_bias\n",
      "transformer.h.2.attn.bias\n",
      "transformer.h.2.attn.masked_bias\n",
      "transformer.h.3.attn.bias\n",
      "transformer.h.3.attn.masked_bias\n",
      "transformer.h.4.attn.bias\n",
      "transformer.h.4.attn.masked_bias\n",
      "transformer.h.5.attn.bias\n",
      "transformer.h.5.attn.masked_bias\n",
      "transformer.h.6.attn.bias\n",
      "transformer.h.6.attn.masked_bias\n",
      "transformer.h.7.attn.bias\n",
      "transformer.h.7.attn.masked_bias\n",
      "transformer.h.8.attn.bias\n",
      "transformer.h.8.attn.masked_bias\n",
      "transformer.h.9.attn.bias\n",
      "transformer.h.9.attn.masked_bias\n",
      "transformer.h.10.attn.bias\n",
      "transformer.h.10.attn.masked_bias\n",
      "transformer.h.11.attn.bias\n",
      "transformer.h.11.attn.masked_bias\n",
      "transformer.h.12.attn.bias\n",
      "transformer.h.12.attn.masked_bias\n",
      "transformer.h.13.attn.bias\n",
      "transformer.h.13.attn.masked_bias\n",
      "transformer.h.14.attn.bias\n",
      "transformer.h.14.attn.masked_bias\n",
      "transformer.h.15.attn.bias\n",
      "transformer.h.15.attn.masked_bias\n",
      "transformer.h.16.attn.bias\n",
      "transformer.h.16.attn.masked_bias\n",
      "transformer.h.17.attn.bias\n",
      "transformer.h.17.attn.masked_bias\n",
      "transformer.h.18.attn.bias\n",
      "transformer.h.18.attn.masked_bias\n",
      "transformer.h.19.attn.bias\n",
      "transformer.h.19.attn.masked_bias\n",
      "transformer.h.20.attn.bias\n",
      "transformer.h.20.attn.masked_bias\n",
      "transformer.h.21.attn.bias\n",
      "transformer.h.21.attn.masked_bias\n",
      "transformer.h.22.attn.bias\n",
      "transformer.h.22.attn.masked_bias\n",
      "transformer.h.23.attn.bias\n",
      "transformer.h.23.attn.masked_bias\n",
      "transformer.h.24.attn.bias\n",
      "transformer.h.24.attn.masked_bias\n",
      "transformer.h.25.attn.bias\n",
      "transformer.h.25.attn.masked_bias\n",
      "transformer.h.26.attn.bias\n",
      "transformer.h.26.attn.masked_bias\n",
      "transformer.h.27.attn.bias\n",
      "transformer.h.27.attn.masked_bias\n",
      "v_head.weight\n"
     ]
    }
   ],
   "source": [
    "for key in gptj_rm_modified_state.keys():\n",
    "    if key not in gptj_state:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c09f5855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/mchorse/.cache/huggingface/hub/models--Dahoas--gptj-rm-static/snapshots/dc9bb2f15f4cddace8a812174c3e7afda2308258/hf_ckpt.pt'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85f827f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(gptj_rm_modified_state, checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acd71db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
