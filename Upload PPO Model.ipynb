{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f599a400-849d-4a26-8f04-4912dfa0aac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-09-29 14:56:34,312] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "from trlx.models.modeling_ppo import AutoModelForCausalLMWithHydraValueHead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4f513c9-de92-449f-9c38-4d26533cd3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoConfig\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a163d3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_name = \"lomahony/eleuther-pythia2.8b-hh-sft\"\n",
    "num_layers_unfrozen = 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6629821d-5be8-46aa-a718-010f1d5d9fd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLMWithHydraValueHead(AutoModelForCausalLM.from_config(AutoConfig.from_pretrained(config_name)), num_layers_unfrozen = num_layers_unfrozen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9f9c763a",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(\"checkpoints/ppo_hh/pythia-2.8b/checkpoint_3000/model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "414cebed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['base_model.gpt_neox.layers.0.input_layernorm.weight', 'base_model.gpt_neox.layers.0.input_layernorm.bias', 'base_model.gpt_neox.layers.0.post_attention_layernorm.weight', 'base_model.gpt_neox.layers.0.post_attention_layernorm.bias', 'base_model.gpt_neox.layers.0.attention.query_key_value.weight', 'base_model.gpt_neox.layers.0.attention.query_key_value.bias', 'base_model.gpt_neox.layers.0.attention.dense.weight', 'base_model.gpt_neox.layers.0.attention.dense.bias', 'base_model.gpt_neox.layers.0.mlp.dense_h_to_4h.weight', 'base_model.gpt_neox.layers.0.mlp.dense_h_to_4h.bias', 'base_model.gpt_neox.layers.0.mlp.dense_4h_to_h.weight', 'base_model.gpt_neox.layers.0.mlp.dense_4h_to_h.bias', 'base_model.gpt_neox.layers.1.input_layernorm.weight', 'base_model.gpt_neox.layers.1.input_layernorm.bias', 'base_model.gpt_neox.layers.1.post_attention_layernorm.weight', 'base_model.gpt_neox.layers.1.post_attention_layernorm.bias', 'base_model.gpt_neox.layers.1.attention.query_key_value.weight', 'base_model.gpt_neox.layers.1.attention.query_key_value.bias', 'base_model.gpt_neox.layers.1.attention.dense.weight', 'base_model.gpt_neox.layers.1.attention.dense.bias', 'base_model.gpt_neox.layers.1.mlp.dense_h_to_4h.weight', 'base_model.gpt_neox.layers.1.mlp.dense_h_to_4h.bias', 'base_model.gpt_neox.layers.1.mlp.dense_4h_to_h.weight', 'base_model.gpt_neox.layers.1.mlp.dense_4h_to_h.bias', 'base_model.gpt_neox.layers.2.input_layernorm.weight', 'base_model.gpt_neox.layers.2.input_layernorm.bias', 'base_model.gpt_neox.layers.2.post_attention_layernorm.weight', 'base_model.gpt_neox.layers.2.post_attention_layernorm.bias', 'base_model.gpt_neox.layers.2.attention.query_key_value.weight', 'base_model.gpt_neox.layers.2.attention.query_key_value.bias', 'base_model.gpt_neox.layers.2.attention.dense.weight', 'base_model.gpt_neox.layers.2.attention.dense.bias', 'base_model.gpt_neox.layers.2.mlp.dense_h_to_4h.weight', 'base_model.gpt_neox.layers.2.mlp.dense_h_to_4h.bias', 'base_model.gpt_neox.layers.2.mlp.dense_4h_to_h.weight', 'base_model.gpt_neox.layers.2.mlp.dense_4h_to_h.bias', 'base_model.gpt_neox.layers.3.input_layernorm.weight', 'base_model.gpt_neox.layers.3.input_layernorm.bias', 'base_model.gpt_neox.layers.3.post_attention_layernorm.weight', 'base_model.gpt_neox.layers.3.post_attention_layernorm.bias', 'base_model.gpt_neox.layers.3.attention.query_key_value.weight', 'base_model.gpt_neox.layers.3.attention.query_key_value.bias', 'base_model.gpt_neox.layers.3.attention.dense.weight', 'base_model.gpt_neox.layers.3.attention.dense.bias', 'base_model.gpt_neox.layers.3.mlp.dense_h_to_4h.weight', 'base_model.gpt_neox.layers.3.mlp.dense_h_to_4h.bias', 'base_model.gpt_neox.layers.3.mlp.dense_4h_to_h.weight', 'base_model.gpt_neox.layers.3.mlp.dense_4h_to_h.bias', 'base_model.gpt_neox.layers.4.input_layernorm.weight', 'base_model.gpt_neox.layers.4.input_layernorm.bias', 'base_model.gpt_neox.layers.4.post_attention_layernorm.weight', 'base_model.gpt_neox.layers.4.post_attention_layernorm.bias', 'base_model.gpt_neox.layers.4.attention.query_key_value.weight', 'base_model.gpt_neox.layers.4.attention.query_key_value.bias', 'base_model.gpt_neox.layers.4.attention.dense.weight', 'base_model.gpt_neox.layers.4.attention.dense.bias', 'base_model.gpt_neox.layers.4.mlp.dense_h_to_4h.weight', 'base_model.gpt_neox.layers.4.mlp.dense_h_to_4h.bias', 'base_model.gpt_neox.layers.4.mlp.dense_4h_to_h.weight', 'base_model.gpt_neox.layers.4.mlp.dense_4h_to_h.bias', 'base_model.gpt_neox.layers.5.input_layernorm.weight', 'base_model.gpt_neox.layers.5.input_layernorm.bias', 'base_model.gpt_neox.layers.5.post_attention_layernorm.weight', 'base_model.gpt_neox.layers.5.post_attention_layernorm.bias', 'base_model.gpt_neox.layers.5.attention.query_key_value.weight', 'base_model.gpt_neox.layers.5.attention.query_key_value.bias', 'base_model.gpt_neox.layers.5.attention.dense.weight', 'base_model.gpt_neox.layers.5.attention.dense.bias', 'base_model.gpt_neox.layers.5.mlp.dense_h_to_4h.weight', 'base_model.gpt_neox.layers.5.mlp.dense_h_to_4h.bias', 'base_model.gpt_neox.layers.5.mlp.dense_4h_to_h.weight', 'base_model.gpt_neox.layers.5.mlp.dense_4h_to_h.bias', 'base_model.gpt_neox.layers.6.input_layernorm.weight', 'base_model.gpt_neox.layers.6.input_layernorm.bias', 'base_model.gpt_neox.layers.6.post_attention_layernorm.weight', 'base_model.gpt_neox.layers.6.post_attention_layernorm.bias', 'base_model.gpt_neox.layers.6.attention.query_key_value.weight', 'base_model.gpt_neox.layers.6.attention.query_key_value.bias', 'base_model.gpt_neox.layers.6.attention.dense.weight', 'base_model.gpt_neox.layers.6.attention.dense.bias', 'base_model.gpt_neox.layers.6.mlp.dense_h_to_4h.weight', 'base_model.gpt_neox.layers.6.mlp.dense_h_to_4h.bias', 'base_model.gpt_neox.layers.6.mlp.dense_4h_to_h.weight', 'base_model.gpt_neox.layers.6.mlp.dense_4h_to_h.bias', 'base_model.gpt_neox.layers.7.input_layernorm.weight', 'base_model.gpt_neox.layers.7.input_layernorm.bias', 'base_model.gpt_neox.layers.7.post_attention_layernorm.weight', 'base_model.gpt_neox.layers.7.post_attention_layernorm.bias', 'base_model.gpt_neox.layers.7.attention.query_key_value.weight', 'base_model.gpt_neox.layers.7.attention.query_key_value.bias', 'base_model.gpt_neox.layers.7.attention.dense.weight', 'base_model.gpt_neox.layers.7.attention.dense.bias', 'base_model.gpt_neox.layers.7.mlp.dense_h_to_4h.weight', 'base_model.gpt_neox.layers.7.mlp.dense_h_to_4h.bias', 'base_model.gpt_neox.layers.7.mlp.dense_4h_to_h.weight', 'base_model.gpt_neox.layers.7.mlp.dense_4h_to_h.bias', 'base_model.gpt_neox.layers.8.input_layernorm.weight', 'base_model.gpt_neox.layers.8.input_layernorm.bias', 'base_model.gpt_neox.layers.8.post_attention_layernorm.weight', 'base_model.gpt_neox.layers.8.post_attention_layernorm.bias', 'base_model.gpt_neox.layers.8.attention.query_key_value.weight', 'base_model.gpt_neox.layers.8.attention.query_key_value.bias', 'base_model.gpt_neox.layers.8.attention.dense.weight', 'base_model.gpt_neox.layers.8.attention.dense.bias', 'base_model.gpt_neox.layers.8.mlp.dense_h_to_4h.weight', 'base_model.gpt_neox.layers.8.mlp.dense_h_to_4h.bias', 'base_model.gpt_neox.layers.8.mlp.dense_4h_to_h.weight', 'base_model.gpt_neox.layers.8.mlp.dense_4h_to_h.bias', 'base_model.gpt_neox.layers.9.input_layernorm.weight', 'base_model.gpt_neox.layers.9.input_layernorm.bias', 'base_model.gpt_neox.layers.9.post_attention_layernorm.weight', 'base_model.gpt_neox.layers.9.post_attention_layernorm.bias', 'base_model.gpt_neox.layers.9.attention.query_key_value.weight', 'base_model.gpt_neox.layers.9.attention.query_key_value.bias', 'base_model.gpt_neox.layers.9.attention.dense.weight', 'base_model.gpt_neox.layers.9.attention.dense.bias', 'base_model.gpt_neox.layers.9.mlp.dense_h_to_4h.weight', 'base_model.gpt_neox.layers.9.mlp.dense_h_to_4h.bias', 'base_model.gpt_neox.layers.9.mlp.dense_4h_to_h.weight', 'base_model.gpt_neox.layers.9.mlp.dense_4h_to_h.bias', 'base_model.gpt_neox.layers.10.input_layernorm.weight', 'base_model.gpt_neox.layers.10.input_layernorm.bias', 'base_model.gpt_neox.layers.10.post_attention_layernorm.weight', 'base_model.gpt_neox.layers.10.post_attention_layernorm.bias', 'base_model.gpt_neox.layers.10.attention.query_key_value.weight', 'base_model.gpt_neox.layers.10.attention.query_key_value.bias', 'base_model.gpt_neox.layers.10.attention.dense.weight', 'base_model.gpt_neox.layers.10.attention.dense.bias', 'base_model.gpt_neox.layers.10.mlp.dense_h_to_4h.weight', 'base_model.gpt_neox.layers.10.mlp.dense_h_to_4h.bias', 'base_model.gpt_neox.layers.10.mlp.dense_4h_to_h.weight', 'base_model.gpt_neox.layers.10.mlp.dense_4h_to_h.bias', 'base_model.gpt_neox.layers.11.input_layernorm.weight', 'base_model.gpt_neox.layers.11.input_layernorm.bias', 'base_model.gpt_neox.layers.11.post_attention_layernorm.weight', 'base_model.gpt_neox.layers.11.post_attention_layernorm.bias', 'base_model.gpt_neox.layers.11.attention.query_key_value.weight', 'base_model.gpt_neox.layers.11.attention.query_key_value.bias', 'base_model.gpt_neox.layers.11.attention.dense.weight', 'base_model.gpt_neox.layers.11.attention.dense.bias', 'base_model.gpt_neox.layers.11.mlp.dense_h_to_4h.weight', 'base_model.gpt_neox.layers.11.mlp.dense_h_to_4h.bias', 'base_model.gpt_neox.layers.11.mlp.dense_4h_to_h.weight', 'base_model.gpt_neox.layers.11.mlp.dense_4h_to_h.bias', 'base_model.gpt_neox.layers.12.input_layernorm.weight', 'base_model.gpt_neox.layers.12.input_layernorm.bias', 'base_model.gpt_neox.layers.12.post_attention_layernorm.weight', 'base_model.gpt_neox.layers.12.post_attention_layernorm.bias', 'base_model.gpt_neox.layers.12.attention.query_key_value.weight', 'base_model.gpt_neox.layers.12.attention.query_key_value.bias', 'base_model.gpt_neox.layers.12.attention.dense.weight', 'base_model.gpt_neox.layers.12.attention.dense.bias', 'base_model.gpt_neox.layers.12.mlp.dense_h_to_4h.weight', 'base_model.gpt_neox.layers.12.mlp.dense_h_to_4h.bias', 'base_model.gpt_neox.layers.12.mlp.dense_4h_to_h.weight', 'base_model.gpt_neox.layers.12.mlp.dense_4h_to_h.bias', 'frozen_head.decoder_blocks.0.input_layernorm.weight', 'frozen_head.decoder_blocks.0.input_layernorm.bias', 'frozen_head.decoder_blocks.0.post_attention_layernorm.weight', 'frozen_head.decoder_blocks.0.post_attention_layernorm.bias', 'frozen_head.decoder_blocks.0.attention.query_key_value.weight', 'frozen_head.decoder_blocks.0.attention.query_key_value.bias', 'frozen_head.decoder_blocks.0.attention.dense.weight', 'frozen_head.decoder_blocks.0.attention.dense.bias', 'frozen_head.decoder_blocks.0.mlp.dense_h_to_4h.weight', 'frozen_head.decoder_blocks.0.mlp.dense_h_to_4h.bias', 'frozen_head.decoder_blocks.0.mlp.dense_4h_to_h.weight', 'frozen_head.decoder_blocks.0.mlp.dense_4h_to_h.bias', 'frozen_head.decoder_blocks.1.input_layernorm.weight', 'frozen_head.decoder_blocks.1.input_layernorm.bias', 'frozen_head.decoder_blocks.1.post_attention_layernorm.weight', 'frozen_head.decoder_blocks.1.post_attention_layernorm.bias', 'frozen_head.decoder_blocks.1.attention.query_key_value.weight', 'frozen_head.decoder_blocks.1.attention.query_key_value.bias', 'frozen_head.decoder_blocks.1.attention.dense.weight', 'frozen_head.decoder_blocks.1.attention.dense.bias', 'frozen_head.decoder_blocks.1.mlp.dense_h_to_4h.weight', 'frozen_head.decoder_blocks.1.mlp.dense_h_to_4h.bias', 'frozen_head.decoder_blocks.1.mlp.dense_4h_to_h.weight', 'frozen_head.decoder_blocks.1.mlp.dense_4h_to_h.bias', 'frozen_head.decoder_blocks.2.input_layernorm.weight', 'frozen_head.decoder_blocks.2.input_layernorm.bias', 'frozen_head.decoder_blocks.2.post_attention_layernorm.weight', 'frozen_head.decoder_blocks.2.post_attention_layernorm.bias', 'frozen_head.decoder_blocks.2.attention.query_key_value.weight', 'frozen_head.decoder_blocks.2.attention.query_key_value.bias', 'frozen_head.decoder_blocks.2.attention.dense.weight', 'frozen_head.decoder_blocks.2.attention.dense.bias', 'frozen_head.decoder_blocks.2.mlp.dense_h_to_4h.weight', 'frozen_head.decoder_blocks.2.mlp.dense_h_to_4h.bias', 'frozen_head.decoder_blocks.2.mlp.dense_4h_to_h.weight', 'frozen_head.decoder_blocks.2.mlp.dense_4h_to_h.bias', 'frozen_head.decoder_blocks.3.input_layernorm.weight', 'frozen_head.decoder_blocks.3.input_layernorm.bias', 'frozen_head.decoder_blocks.3.post_attention_layernorm.weight', 'frozen_head.decoder_blocks.3.post_attention_layernorm.bias', 'frozen_head.decoder_blocks.3.attention.query_key_value.weight', 'frozen_head.decoder_blocks.3.attention.query_key_value.bias', 'frozen_head.decoder_blocks.3.attention.dense.weight', 'frozen_head.decoder_blocks.3.attention.dense.bias', 'frozen_head.decoder_blocks.3.mlp.dense_h_to_4h.weight', 'frozen_head.decoder_blocks.3.mlp.dense_h_to_4h.bias', 'frozen_head.decoder_blocks.3.mlp.dense_4h_to_h.weight', 'frozen_head.decoder_blocks.3.mlp.dense_4h_to_h.bias', 'frozen_head.decoder_blocks.4.input_layernorm.weight', 'frozen_head.decoder_blocks.4.input_layernorm.bias', 'frozen_head.decoder_blocks.4.post_attention_layernorm.weight', 'frozen_head.decoder_blocks.4.post_attention_layernorm.bias', 'frozen_head.decoder_blocks.4.attention.query_key_value.weight', 'frozen_head.decoder_blocks.4.attention.query_key_value.bias', 'frozen_head.decoder_blocks.4.attention.dense.weight', 'frozen_head.decoder_blocks.4.attention.dense.bias', 'frozen_head.decoder_blocks.4.mlp.dense_h_to_4h.weight', 'frozen_head.decoder_blocks.4.mlp.dense_h_to_4h.bias', 'frozen_head.decoder_blocks.4.mlp.dense_4h_to_h.weight', 'frozen_head.decoder_blocks.4.mlp.dense_4h_to_h.bias', 'frozen_head.decoder_blocks.5.input_layernorm.weight', 'frozen_head.decoder_blocks.5.input_layernorm.bias', 'frozen_head.decoder_blocks.5.post_attention_layernorm.weight', 'frozen_head.decoder_blocks.5.post_attention_layernorm.bias', 'frozen_head.decoder_blocks.5.attention.query_key_value.weight', 'frozen_head.decoder_blocks.5.attention.query_key_value.bias', 'frozen_head.decoder_blocks.5.attention.dense.weight', 'frozen_head.decoder_blocks.5.attention.dense.bias', 'frozen_head.decoder_blocks.5.mlp.dense_h_to_4h.weight', 'frozen_head.decoder_blocks.5.mlp.dense_h_to_4h.bias', 'frozen_head.decoder_blocks.5.mlp.dense_4h_to_h.weight', 'frozen_head.decoder_blocks.5.mlp.dense_4h_to_h.bias', 'frozen_head.decoder_blocks.6.input_layernorm.weight', 'frozen_head.decoder_blocks.6.input_layernorm.bias', 'frozen_head.decoder_blocks.6.post_attention_layernorm.weight', 'frozen_head.decoder_blocks.6.post_attention_layernorm.bias', 'frozen_head.decoder_blocks.6.attention.query_key_value.weight', 'frozen_head.decoder_blocks.6.attention.query_key_value.bias', 'frozen_head.decoder_blocks.6.attention.dense.weight', 'frozen_head.decoder_blocks.6.attention.dense.bias', 'frozen_head.decoder_blocks.6.mlp.dense_h_to_4h.weight', 'frozen_head.decoder_blocks.6.mlp.dense_h_to_4h.bias', 'frozen_head.decoder_blocks.6.mlp.dense_4h_to_h.weight', 'frozen_head.decoder_blocks.6.mlp.dense_4h_to_h.bias', 'frozen_head.decoder_blocks.7.input_layernorm.weight', 'frozen_head.decoder_blocks.7.input_layernorm.bias', 'frozen_head.decoder_blocks.7.post_attention_layernorm.weight', 'frozen_head.decoder_blocks.7.post_attention_layernorm.bias', 'frozen_head.decoder_blocks.7.attention.query_key_value.weight', 'frozen_head.decoder_blocks.7.attention.query_key_value.bias', 'frozen_head.decoder_blocks.7.attention.dense.weight', 'frozen_head.decoder_blocks.7.attention.dense.bias', 'frozen_head.decoder_blocks.7.mlp.dense_h_to_4h.weight', 'frozen_head.decoder_blocks.7.mlp.dense_h_to_4h.bias', 'frozen_head.decoder_blocks.7.mlp.dense_4h_to_h.weight', 'frozen_head.decoder_blocks.7.mlp.dense_4h_to_h.bias', 'frozen_head.decoder_blocks.8.input_layernorm.weight', 'frozen_head.decoder_blocks.8.input_layernorm.bias', 'frozen_head.decoder_blocks.8.post_attention_layernorm.weight', 'frozen_head.decoder_blocks.8.post_attention_layernorm.bias', 'frozen_head.decoder_blocks.8.attention.query_key_value.weight', 'frozen_head.decoder_blocks.8.attention.query_key_value.bias', 'frozen_head.decoder_blocks.8.attention.dense.weight', 'frozen_head.decoder_blocks.8.attention.dense.bias', 'frozen_head.decoder_blocks.8.mlp.dense_h_to_4h.weight', 'frozen_head.decoder_blocks.8.mlp.dense_h_to_4h.bias', 'frozen_head.decoder_blocks.8.mlp.dense_4h_to_h.weight', 'frozen_head.decoder_blocks.8.mlp.dense_4h_to_h.bias', 'frozen_head.decoder_blocks.9.input_layernorm.weight', 'frozen_head.decoder_blocks.9.input_layernorm.bias', 'frozen_head.decoder_blocks.9.post_attention_layernorm.weight', 'frozen_head.decoder_blocks.9.post_attention_layernorm.bias', 'frozen_head.decoder_blocks.9.attention.query_key_value.weight', 'frozen_head.decoder_blocks.9.attention.query_key_value.bias', 'frozen_head.decoder_blocks.9.attention.dense.weight', 'frozen_head.decoder_blocks.9.attention.dense.bias', 'frozen_head.decoder_blocks.9.mlp.dense_h_to_4h.weight', 'frozen_head.decoder_blocks.9.mlp.dense_h_to_4h.bias', 'frozen_head.decoder_blocks.9.mlp.dense_4h_to_h.weight', 'frozen_head.decoder_blocks.9.mlp.dense_4h_to_h.bias', 'frozen_head.decoder_blocks.10.input_layernorm.weight', 'frozen_head.decoder_blocks.10.input_layernorm.bias', 'frozen_head.decoder_blocks.10.post_attention_layernorm.weight', 'frozen_head.decoder_blocks.10.post_attention_layernorm.bias', 'frozen_head.decoder_blocks.10.attention.query_key_value.weight', 'frozen_head.decoder_blocks.10.attention.query_key_value.bias', 'frozen_head.decoder_blocks.10.attention.dense.weight', 'frozen_head.decoder_blocks.10.attention.dense.bias', 'frozen_head.decoder_blocks.10.mlp.dense_h_to_4h.weight', 'frozen_head.decoder_blocks.10.mlp.dense_h_to_4h.bias', 'frozen_head.decoder_blocks.10.mlp.dense_4h_to_h.weight', 'frozen_head.decoder_blocks.10.mlp.dense_4h_to_h.bias', 'frozen_head.decoder_blocks.11.input_layernorm.weight', 'frozen_head.decoder_blocks.11.input_layernorm.bias', 'frozen_head.decoder_blocks.11.post_attention_layernorm.weight', 'frozen_head.decoder_blocks.11.post_attention_layernorm.bias', 'frozen_head.decoder_blocks.11.attention.query_key_value.weight', 'frozen_head.decoder_blocks.11.attention.query_key_value.bias', 'frozen_head.decoder_blocks.11.attention.dense.weight', 'frozen_head.decoder_blocks.11.attention.dense.bias', 'frozen_head.decoder_blocks.11.mlp.dense_h_to_4h.weight', 'frozen_head.decoder_blocks.11.mlp.dense_h_to_4h.bias', 'frozen_head.decoder_blocks.11.mlp.dense_4h_to_h.weight', 'frozen_head.decoder_blocks.11.mlp.dense_4h_to_h.bias', 'frozen_head.decoder_blocks.12.input_layernorm.weight', 'frozen_head.decoder_blocks.12.input_layernorm.bias', 'frozen_head.decoder_blocks.12.post_attention_layernorm.weight', 'frozen_head.decoder_blocks.12.post_attention_layernorm.bias', 'frozen_head.decoder_blocks.12.attention.query_key_value.weight', 'frozen_head.decoder_blocks.12.attention.query_key_value.bias', 'frozen_head.decoder_blocks.12.attention.dense.weight', 'frozen_head.decoder_blocks.12.attention.dense.bias', 'frozen_head.decoder_blocks.12.mlp.dense_h_to_4h.weight', 'frozen_head.decoder_blocks.12.mlp.dense_h_to_4h.bias', 'frozen_head.decoder_blocks.12.mlp.dense_4h_to_h.weight', 'frozen_head.decoder_blocks.12.mlp.dense_4h_to_h.bias', 'frozen_head.decoder_blocks.13.input_layernorm.weight', 'frozen_head.decoder_blocks.13.input_layernorm.bias', 'frozen_head.decoder_blocks.13.post_attention_layernorm.weight', 'frozen_head.decoder_blocks.13.post_attention_layernorm.bias', 'frozen_head.decoder_blocks.13.attention.query_key_value.weight', 'frozen_head.decoder_blocks.13.attention.query_key_value.bias', 'frozen_head.decoder_blocks.13.attention.dense.weight', 'frozen_head.decoder_blocks.13.attention.dense.bias', 'frozen_head.decoder_blocks.13.mlp.dense_h_to_4h.weight', 'frozen_head.decoder_blocks.13.mlp.dense_h_to_4h.bias', 'frozen_head.decoder_blocks.13.mlp.dense_4h_to_h.weight', 'frozen_head.decoder_blocks.13.mlp.dense_4h_to_h.bias', 'frozen_head.decoder_blocks.14.input_layernorm.weight', 'frozen_head.decoder_blocks.14.input_layernorm.bias', 'frozen_head.decoder_blocks.14.post_attention_layernorm.weight', 'frozen_head.decoder_blocks.14.post_attention_layernorm.bias', 'frozen_head.decoder_blocks.14.attention.query_key_value.weight', 'frozen_head.decoder_blocks.14.attention.query_key_value.bias', 'frozen_head.decoder_blocks.14.attention.dense.weight', 'frozen_head.decoder_blocks.14.attention.dense.bias', 'frozen_head.decoder_blocks.14.mlp.dense_h_to_4h.weight', 'frozen_head.decoder_blocks.14.mlp.dense_h_to_4h.bias', 'frozen_head.decoder_blocks.14.mlp.dense_4h_to_h.weight', 'frozen_head.decoder_blocks.14.mlp.dense_4h_to_h.bias', 'frozen_head.decoder_blocks.15.input_layernorm.weight', 'frozen_head.decoder_blocks.15.input_layernorm.bias', 'frozen_head.decoder_blocks.15.post_attention_layernorm.weight', 'frozen_head.decoder_blocks.15.post_attention_layernorm.bias', 'frozen_head.decoder_blocks.15.attention.query_key_value.weight', 'frozen_head.decoder_blocks.15.attention.query_key_value.bias', 'frozen_head.decoder_blocks.15.attention.dense.weight', 'frozen_head.decoder_blocks.15.attention.dense.bias', 'frozen_head.decoder_blocks.15.mlp.dense_h_to_4h.weight', 'frozen_head.decoder_blocks.15.mlp.dense_h_to_4h.bias', 'frozen_head.decoder_blocks.15.mlp.dense_4h_to_h.weight', 'frozen_head.decoder_blocks.15.mlp.dense_4h_to_h.bias', 'frozen_head.decoder_blocks.16.input_layernorm.weight', 'frozen_head.decoder_blocks.16.input_layernorm.bias', 'frozen_head.decoder_blocks.16.post_attention_layernorm.weight', 'frozen_head.decoder_blocks.16.post_attention_layernorm.bias', 'frozen_head.decoder_blocks.16.attention.query_key_value.weight', 'frozen_head.decoder_blocks.16.attention.query_key_value.bias', 'frozen_head.decoder_blocks.16.attention.dense.weight', 'frozen_head.decoder_blocks.16.attention.dense.bias', 'frozen_head.decoder_blocks.16.mlp.dense_h_to_4h.weight', 'frozen_head.decoder_blocks.16.mlp.dense_h_to_4h.bias', 'frozen_head.decoder_blocks.16.mlp.dense_4h_to_h.weight', 'frozen_head.decoder_blocks.16.mlp.dense_4h_to_h.bias', 'frozen_head.decoder_blocks.17.input_layernorm.weight', 'frozen_head.decoder_blocks.17.input_layernorm.bias', 'frozen_head.decoder_blocks.17.post_attention_layernorm.weight', 'frozen_head.decoder_blocks.17.post_attention_layernorm.bias', 'frozen_head.decoder_blocks.17.attention.query_key_value.weight', 'frozen_head.decoder_blocks.17.attention.query_key_value.bias', 'frozen_head.decoder_blocks.17.attention.dense.weight', 'frozen_head.decoder_blocks.17.attention.dense.bias', 'frozen_head.decoder_blocks.17.mlp.dense_h_to_4h.weight', 'frozen_head.decoder_blocks.17.mlp.dense_h_to_4h.bias', 'frozen_head.decoder_blocks.17.mlp.dense_4h_to_h.weight', 'frozen_head.decoder_blocks.17.mlp.dense_4h_to_h.bias', 'frozen_head.decoder_blocks.18.input_layernorm.weight', 'frozen_head.decoder_blocks.18.input_layernorm.bias', 'frozen_head.decoder_blocks.18.post_attention_layernorm.weight', 'frozen_head.decoder_blocks.18.post_attention_layernorm.bias', 'frozen_head.decoder_blocks.18.attention.query_key_value.weight', 'frozen_head.decoder_blocks.18.attention.query_key_value.bias', 'frozen_head.decoder_blocks.18.attention.dense.weight', 'frozen_head.decoder_blocks.18.attention.dense.bias', 'frozen_head.decoder_blocks.18.mlp.dense_h_to_4h.weight', 'frozen_head.decoder_blocks.18.mlp.dense_h_to_4h.bias', 'frozen_head.decoder_blocks.18.mlp.dense_4h_to_h.weight', 'frozen_head.decoder_blocks.18.mlp.dense_4h_to_h.bias', 'frozen_head.final_norm.weight', 'frozen_head.final_norm.bias', 'frozen_head.lm_head.weight', 'base_model.gpt_neox.embed_in.weight', 'base_model.gpt_neox.layers.13.input_layernorm.weight', 'base_model.gpt_neox.layers.13.input_layernorm.bias', 'base_model.gpt_neox.layers.13.post_attention_layernorm.weight', 'base_model.gpt_neox.layers.13.post_attention_layernorm.bias', 'base_model.gpt_neox.layers.13.attention.query_key_value.weight', 'base_model.gpt_neox.layers.13.attention.query_key_value.bias', 'base_model.gpt_neox.layers.13.attention.dense.weight', 'base_model.gpt_neox.layers.13.attention.dense.bias', 'base_model.gpt_neox.layers.13.mlp.dense_h_to_4h.weight', 'base_model.gpt_neox.layers.13.mlp.dense_h_to_4h.bias', 'base_model.gpt_neox.layers.13.mlp.dense_4h_to_h.weight', 'base_model.gpt_neox.layers.13.mlp.dense_4h_to_h.bias', 'base_model.gpt_neox.layers.14.input_layernorm.weight', 'base_model.gpt_neox.layers.14.input_layernorm.bias', 'base_model.gpt_neox.layers.14.post_attention_layernorm.weight', 'base_model.gpt_neox.layers.14.post_attention_layernorm.bias', 'base_model.gpt_neox.layers.14.attention.query_key_value.weight', 'base_model.gpt_neox.layers.14.attention.query_key_value.bias', 'base_model.gpt_neox.layers.14.attention.dense.weight', 'base_model.gpt_neox.layers.14.attention.dense.bias', 'base_model.gpt_neox.layers.14.mlp.dense_h_to_4h.weight', 'base_model.gpt_neox.layers.14.mlp.dense_h_to_4h.bias', 'base_model.gpt_neox.layers.14.mlp.dense_4h_to_h.weight', 'base_model.gpt_neox.layers.14.mlp.dense_4h_to_h.bias', 'base_model.gpt_neox.layers.15.input_layernorm.weight', 'base_model.gpt_neox.layers.15.input_layernorm.bias', 'base_model.gpt_neox.layers.15.post_attention_layernorm.weight', 'base_model.gpt_neox.layers.15.post_attention_layernorm.bias', 'base_model.gpt_neox.layers.15.attention.query_key_value.weight', 'base_model.gpt_neox.layers.15.attention.query_key_value.bias', 'base_model.gpt_neox.layers.15.attention.dense.weight', 'base_model.gpt_neox.layers.15.attention.dense.bias', 'base_model.gpt_neox.layers.15.mlp.dense_h_to_4h.weight', 'base_model.gpt_neox.layers.15.mlp.dense_h_to_4h.bias', 'base_model.gpt_neox.layers.15.mlp.dense_4h_to_h.weight', 'base_model.gpt_neox.layers.15.mlp.dense_4h_to_h.bias', 'base_model.gpt_neox.layers.16.input_layernorm.weight', 'base_model.gpt_neox.layers.16.input_layernorm.bias', 'base_model.gpt_neox.layers.16.post_attention_layernorm.weight', 'base_model.gpt_neox.layers.16.post_attention_layernorm.bias', 'base_model.gpt_neox.layers.16.attention.query_key_value.weight', 'base_model.gpt_neox.layers.16.attention.query_key_value.bias', 'base_model.gpt_neox.layers.16.attention.dense.weight', 'base_model.gpt_neox.layers.16.attention.dense.bias', 'base_model.gpt_neox.layers.16.mlp.dense_h_to_4h.weight', 'base_model.gpt_neox.layers.16.mlp.dense_h_to_4h.bias', 'base_model.gpt_neox.layers.16.mlp.dense_4h_to_h.weight', 'base_model.gpt_neox.layers.16.mlp.dense_4h_to_h.bias', 'base_model.gpt_neox.layers.17.input_layernorm.weight', 'base_model.gpt_neox.layers.17.input_layernorm.bias', 'base_model.gpt_neox.layers.17.post_attention_layernorm.weight', 'base_model.gpt_neox.layers.17.post_attention_layernorm.bias', 'base_model.gpt_neox.layers.17.attention.query_key_value.weight', 'base_model.gpt_neox.layers.17.attention.query_key_value.bias', 'base_model.gpt_neox.layers.17.attention.dense.weight', 'base_model.gpt_neox.layers.17.attention.dense.bias', 'base_model.gpt_neox.layers.17.mlp.dense_h_to_4h.weight', 'base_model.gpt_neox.layers.17.mlp.dense_h_to_4h.bias', 'base_model.gpt_neox.layers.17.mlp.dense_4h_to_h.weight', 'base_model.gpt_neox.layers.17.mlp.dense_4h_to_h.bias', 'base_model.gpt_neox.layers.18.input_layernorm.weight', 'base_model.gpt_neox.layers.18.input_layernorm.bias', 'base_model.gpt_neox.layers.18.post_attention_layernorm.weight', 'base_model.gpt_neox.layers.18.post_attention_layernorm.bias', 'base_model.gpt_neox.layers.18.attention.query_key_value.weight', 'base_model.gpt_neox.layers.18.attention.query_key_value.bias', 'base_model.gpt_neox.layers.18.attention.dense.weight', 'base_model.gpt_neox.layers.18.attention.dense.bias', 'base_model.gpt_neox.layers.18.mlp.dense_h_to_4h.weight', 'base_model.gpt_neox.layers.18.mlp.dense_h_to_4h.bias', 'base_model.gpt_neox.layers.18.mlp.dense_4h_to_h.weight', 'base_model.gpt_neox.layers.18.mlp.dense_4h_to_h.bias', 'base_model.gpt_neox.layers.19.input_layernorm.weight', 'base_model.gpt_neox.layers.19.input_layernorm.bias', 'base_model.gpt_neox.layers.19.post_attention_layernorm.weight', 'base_model.gpt_neox.layers.19.post_attention_layernorm.bias', 'base_model.gpt_neox.layers.19.attention.query_key_value.weight', 'base_model.gpt_neox.layers.19.attention.query_key_value.bias', 'base_model.gpt_neox.layers.19.attention.dense.weight', 'base_model.gpt_neox.layers.19.attention.dense.bias', 'base_model.gpt_neox.layers.19.mlp.dense_h_to_4h.weight', 'base_model.gpt_neox.layers.19.mlp.dense_h_to_4h.bias', 'base_model.gpt_neox.layers.19.mlp.dense_4h_to_h.weight', 'base_model.gpt_neox.layers.19.mlp.dense_4h_to_h.bias', 'base_model.gpt_neox.layers.20.input_layernorm.weight', 'base_model.gpt_neox.layers.20.input_layernorm.bias', 'base_model.gpt_neox.layers.20.post_attention_layernorm.weight', 'base_model.gpt_neox.layers.20.post_attention_layernorm.bias', 'base_model.gpt_neox.layers.20.attention.query_key_value.weight', 'base_model.gpt_neox.layers.20.attention.query_key_value.bias', 'base_model.gpt_neox.layers.20.attention.dense.weight', 'base_model.gpt_neox.layers.20.attention.dense.bias', 'base_model.gpt_neox.layers.20.mlp.dense_h_to_4h.weight', 'base_model.gpt_neox.layers.20.mlp.dense_h_to_4h.bias', 'base_model.gpt_neox.layers.20.mlp.dense_4h_to_h.weight', 'base_model.gpt_neox.layers.20.mlp.dense_4h_to_h.bias', 'base_model.gpt_neox.layers.21.input_layernorm.weight', 'base_model.gpt_neox.layers.21.input_layernorm.bias', 'base_model.gpt_neox.layers.21.post_attention_layernorm.weight', 'base_model.gpt_neox.layers.21.post_attention_layernorm.bias', 'base_model.gpt_neox.layers.21.attention.query_key_value.weight', 'base_model.gpt_neox.layers.21.attention.query_key_value.bias', 'base_model.gpt_neox.layers.21.attention.dense.weight', 'base_model.gpt_neox.layers.21.attention.dense.bias', 'base_model.gpt_neox.layers.21.mlp.dense_h_to_4h.weight', 'base_model.gpt_neox.layers.21.mlp.dense_h_to_4h.bias', 'base_model.gpt_neox.layers.21.mlp.dense_4h_to_h.weight', 'base_model.gpt_neox.layers.21.mlp.dense_4h_to_h.bias', 'base_model.gpt_neox.layers.22.input_layernorm.weight', 'base_model.gpt_neox.layers.22.input_layernorm.bias', 'base_model.gpt_neox.layers.22.post_attention_layernorm.weight', 'base_model.gpt_neox.layers.22.post_attention_layernorm.bias', 'base_model.gpt_neox.layers.22.attention.query_key_value.weight', 'base_model.gpt_neox.layers.22.attention.query_key_value.bias', 'base_model.gpt_neox.layers.22.attention.dense.weight', 'base_model.gpt_neox.layers.22.attention.dense.bias', 'base_model.gpt_neox.layers.22.mlp.dense_h_to_4h.weight', 'base_model.gpt_neox.layers.22.mlp.dense_h_to_4h.bias', 'base_model.gpt_neox.layers.22.mlp.dense_4h_to_h.weight', 'base_model.gpt_neox.layers.22.mlp.dense_4h_to_h.bias', 'base_model.gpt_neox.layers.23.input_layernorm.weight', 'base_model.gpt_neox.layers.23.input_layernorm.bias', 'base_model.gpt_neox.layers.23.post_attention_layernorm.weight', 'base_model.gpt_neox.layers.23.post_attention_layernorm.bias', 'base_model.gpt_neox.layers.23.attention.query_key_value.weight', 'base_model.gpt_neox.layers.23.attention.query_key_value.bias', 'base_model.gpt_neox.layers.23.attention.dense.weight', 'base_model.gpt_neox.layers.23.attention.dense.bias', 'base_model.gpt_neox.layers.23.mlp.dense_h_to_4h.weight', 'base_model.gpt_neox.layers.23.mlp.dense_h_to_4h.bias', 'base_model.gpt_neox.layers.23.mlp.dense_4h_to_h.weight', 'base_model.gpt_neox.layers.23.mlp.dense_4h_to_h.bias', 'base_model.gpt_neox.layers.24.input_layernorm.weight', 'base_model.gpt_neox.layers.24.input_layernorm.bias', 'base_model.gpt_neox.layers.24.post_attention_layernorm.weight', 'base_model.gpt_neox.layers.24.post_attention_layernorm.bias', 'base_model.gpt_neox.layers.24.attention.query_key_value.weight', 'base_model.gpt_neox.layers.24.attention.query_key_value.bias', 'base_model.gpt_neox.layers.24.attention.dense.weight', 'base_model.gpt_neox.layers.24.attention.dense.bias', 'base_model.gpt_neox.layers.24.mlp.dense_h_to_4h.weight', 'base_model.gpt_neox.layers.24.mlp.dense_h_to_4h.bias', 'base_model.gpt_neox.layers.24.mlp.dense_4h_to_h.weight', 'base_model.gpt_neox.layers.24.mlp.dense_4h_to_h.bias', 'base_model.gpt_neox.layers.25.input_layernorm.weight', 'base_model.gpt_neox.layers.25.input_layernorm.bias', 'base_model.gpt_neox.layers.25.post_attention_layernorm.weight', 'base_model.gpt_neox.layers.25.post_attention_layernorm.bias', 'base_model.gpt_neox.layers.25.attention.query_key_value.weight', 'base_model.gpt_neox.layers.25.attention.query_key_value.bias', 'base_model.gpt_neox.layers.25.attention.dense.weight', 'base_model.gpt_neox.layers.25.attention.dense.bias', 'base_model.gpt_neox.layers.25.mlp.dense_h_to_4h.weight', 'base_model.gpt_neox.layers.25.mlp.dense_h_to_4h.bias', 'base_model.gpt_neox.layers.25.mlp.dense_4h_to_h.weight', 'base_model.gpt_neox.layers.25.mlp.dense_4h_to_h.bias', 'base_model.gpt_neox.layers.26.input_layernorm.weight', 'base_model.gpt_neox.layers.26.input_layernorm.bias', 'base_model.gpt_neox.layers.26.post_attention_layernorm.weight', 'base_model.gpt_neox.layers.26.post_attention_layernorm.bias', 'base_model.gpt_neox.layers.26.attention.query_key_value.weight', 'base_model.gpt_neox.layers.26.attention.query_key_value.bias', 'base_model.gpt_neox.layers.26.attention.dense.weight', 'base_model.gpt_neox.layers.26.attention.dense.bias', 'base_model.gpt_neox.layers.26.mlp.dense_h_to_4h.weight', 'base_model.gpt_neox.layers.26.mlp.dense_h_to_4h.bias', 'base_model.gpt_neox.layers.26.mlp.dense_4h_to_h.weight', 'base_model.gpt_neox.layers.26.mlp.dense_4h_to_h.bias', 'base_model.gpt_neox.layers.27.input_layernorm.weight', 'base_model.gpt_neox.layers.27.input_layernorm.bias', 'base_model.gpt_neox.layers.27.post_attention_layernorm.weight', 'base_model.gpt_neox.layers.27.post_attention_layernorm.bias', 'base_model.gpt_neox.layers.27.attention.query_key_value.weight', 'base_model.gpt_neox.layers.27.attention.query_key_value.bias', 'base_model.gpt_neox.layers.27.attention.dense.weight', 'base_model.gpt_neox.layers.27.attention.dense.bias', 'base_model.gpt_neox.layers.27.mlp.dense_h_to_4h.weight', 'base_model.gpt_neox.layers.27.mlp.dense_h_to_4h.bias', 'base_model.gpt_neox.layers.27.mlp.dense_4h_to_h.weight', 'base_model.gpt_neox.layers.27.mlp.dense_4h_to_h.bias', 'base_model.gpt_neox.layers.28.input_layernorm.weight', 'base_model.gpt_neox.layers.28.input_layernorm.bias', 'base_model.gpt_neox.layers.28.post_attention_layernorm.weight', 'base_model.gpt_neox.layers.28.post_attention_layernorm.bias', 'base_model.gpt_neox.layers.28.attention.query_key_value.weight', 'base_model.gpt_neox.layers.28.attention.query_key_value.bias', 'base_model.gpt_neox.layers.28.attention.dense.weight', 'base_model.gpt_neox.layers.28.attention.dense.bias', 'base_model.gpt_neox.layers.28.mlp.dense_h_to_4h.weight', 'base_model.gpt_neox.layers.28.mlp.dense_h_to_4h.bias', 'base_model.gpt_neox.layers.28.mlp.dense_4h_to_h.weight', 'base_model.gpt_neox.layers.28.mlp.dense_4h_to_h.bias', 'base_model.gpt_neox.layers.29.input_layernorm.weight', 'base_model.gpt_neox.layers.29.input_layernorm.bias', 'base_model.gpt_neox.layers.29.post_attention_layernorm.weight', 'base_model.gpt_neox.layers.29.post_attention_layernorm.bias', 'base_model.gpt_neox.layers.29.attention.query_key_value.weight', 'base_model.gpt_neox.layers.29.attention.query_key_value.bias', 'base_model.gpt_neox.layers.29.attention.dense.weight', 'base_model.gpt_neox.layers.29.attention.dense.bias', 'base_model.gpt_neox.layers.29.mlp.dense_h_to_4h.weight', 'base_model.gpt_neox.layers.29.mlp.dense_h_to_4h.bias', 'base_model.gpt_neox.layers.29.mlp.dense_4h_to_h.weight', 'base_model.gpt_neox.layers.29.mlp.dense_4h_to_h.bias', 'base_model.gpt_neox.layers.30.input_layernorm.weight', 'base_model.gpt_neox.layers.30.input_layernorm.bias', 'base_model.gpt_neox.layers.30.post_attention_layernorm.weight', 'base_model.gpt_neox.layers.30.post_attention_layernorm.bias', 'base_model.gpt_neox.layers.30.attention.query_key_value.weight', 'base_model.gpt_neox.layers.30.attention.query_key_value.bias', 'base_model.gpt_neox.layers.30.attention.dense.weight', 'base_model.gpt_neox.layers.30.attention.dense.bias', 'base_model.gpt_neox.layers.30.mlp.dense_h_to_4h.weight', 'base_model.gpt_neox.layers.30.mlp.dense_h_to_4h.bias', 'base_model.gpt_neox.layers.30.mlp.dense_4h_to_h.weight', 'base_model.gpt_neox.layers.30.mlp.dense_4h_to_h.bias', 'base_model.gpt_neox.layers.31.input_layernorm.weight', 'base_model.gpt_neox.layers.31.input_layernorm.bias', 'base_model.gpt_neox.layers.31.post_attention_layernorm.weight', 'base_model.gpt_neox.layers.31.post_attention_layernorm.bias', 'base_model.gpt_neox.layers.31.attention.query_key_value.weight', 'base_model.gpt_neox.layers.31.attention.query_key_value.bias', 'base_model.gpt_neox.layers.31.attention.dense.weight', 'base_model.gpt_neox.layers.31.attention.dense.bias', 'base_model.gpt_neox.layers.31.mlp.dense_h_to_4h.weight', 'base_model.gpt_neox.layers.31.mlp.dense_h_to_4h.bias', 'base_model.gpt_neox.layers.31.mlp.dense_4h_to_h.weight', 'base_model.gpt_neox.layers.31.mlp.dense_4h_to_h.bias', 'base_model.gpt_neox.final_layer_norm.weight', 'base_model.gpt_neox.final_layer_norm.bias', 'base_model.embed_out.weight', 'v_head.0.weight', 'v_head.0.bias', 'v_head.2.weight', 'v_head.2.bias'])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b947ca81-01f5-43d7-8609-83af2b949f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "unused, unexpected = model.load_state_dict(state_dict, strict = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5df3e300",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8959514a24a9437bba7a1a1eeb67109c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00002-of-00002.bin:   0%|          | 0.00/1.20G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85c2b7e213954aec8def1bb7d2cadcff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00001-of-00002.bin:   0%|          | 0.00/10.1G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c427fb7ca5af4fe4be2b488ed4a58e3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/usvsnsp/pythia-2.8b-ppo/commit/d04bbec514807241e8476789ce4ae7002cfb460e', commit_message='Upload model', commit_description='', oid='d04bbec514807241e8476789ce4ae7002cfb460e', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub(\"usvsnsp/pythia-2.8b-ppo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7521b25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/usvsnsp/pythia-2.8b-ppo/commit/88ce11065d11664572528eec8d2edcc44baecc4d', commit_message='Upload tokenizer', commit_description='', oid='88ce11065d11664572528eec8d2edcc44baecc4d', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/pythia-70m\")\n",
    "tokenizer.push_to_hub(\"usvsnsp/pythia-2.8b-ppo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e131fe6c-cff3-45ef-912a-358d7137e5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6f56b48-d4f8-4803-9c6d-dc130f8b9ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = HfApi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ee11534-297f-4aad-8a03-3d37fb381a61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f92b41ff8144161953439e27f00cb9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c2c0f7a62fd4cc7821fd1291841f990",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.bin:   0%|          | 0.00/12.4G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/usvsnsp/pythia-2.8b-ppo/blob/main/raw_model/model.bin'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api.upload_file(\n",
    "    path_or_fileobj = \"checkpoints/ppo_hh/pythia-2.8b/checkpoint_3000/model.bin\",\n",
    "    path_in_repo = 'raw_model/model.bin',\n",
    "    repo_id = 'usvsnsp/pythia-2.8b-ppo',\n",
    "    repo_type = 'model'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3f0bbe8-93c9-4494-a5dc-c4d440043db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The argument `from_transformers` is deprecated, and will be removed in optimum 2.0.  Use `export` instead\n",
      "Framework not specified. Using pt to export to ONNX.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c568e19569ff4caab7916d93205cb123",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Trying to export a gpt_neox model, that is a custom or unsupported architecture for the task text-classification, but no custom onnx configuration was passed as `custom_onnx_configs`. Please refer to https://huggingface.co/docs/optimum/main/en/exporters/onnx/usage_guides/export_a_model#custom-export-of-transformers-models for an example on how to export custom models. For the task text-classification, the Optimum ONNX exporter supports natively the architectures: ['albert', 'bart', 'bert', 'bloom', 'camembert', 'convbert', 'data2vec_text', 'deberta', 'deberta_v2', 'distilbert', 'electra', 'flaubert', 'ibert', 'layoutlm', 'layoutlmv3', 'lilt', 'mbart', 'mobilebert', 'mpnet', 'nystromformer', 'perceiver', 'roberta', 'roformer', 'squeezebert', 'xlm', 'xlm_roberta'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m reward_model \u001b[38;5;241m=\u001b[39m \u001b[43mORTModelForSequenceClassification\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43musvsnsp/pythia-6.9b-rm-full-hh-rlhf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfrom_transformers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m      4\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/ssd-1/pythia-rlhf/venv/lib/python3.9/site-packages/optimum/onnxruntime/modeling_ort.py:647\u001b[0m, in \u001b[0;36mORTModel.from_pretrained\u001b[0;34m(cls, model_id, export, force_download, use_auth_token, cache_dir, subfolder, config, local_files_only, provider, session_options, provider_options, use_io_binding, **kwargs)\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;129m@add_start_docstrings\u001b[39m(FROM_PRETRAINED_START_DOCSTRING)\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_pretrained\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    615\u001b[0m ):\n\u001b[1;32m    616\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    617\u001b[0m \u001b[38;5;124;03m    provider (`str`, defaults to `\"CPUExecutionProvider\"`):\u001b[39;00m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;124;03m        ONNX Runtime provider to use for loading the model. See https://onnxruntime.ai/docs/execution-providers/ for\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    645\u001b[0m \u001b[38;5;124;03m        `ORTModel`: The loaded ORTModel model.\u001b[39;00m\n\u001b[1;32m    646\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 647\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    652\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    654\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    655\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprovider\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprovider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    657\u001b[0m \u001b[43m        \u001b[49m\u001b[43msession_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprovider_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprovider_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_io_binding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_io_binding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    660\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    661\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/ssd-1/pythia-rlhf/venv/lib/python3.9/site-packages/optimum/modeling_base.py:372\u001b[0m, in \u001b[0;36mOptimizedModel.from_pretrained\u001b[0;34m(cls, model_id, export, force_download, use_auth_token, cache_dir, subfolder, config, local_files_only, trust_remote_code, revision, **kwargs)\u001b[0m\n\u001b[1;32m    369\u001b[0m     trust_remote_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    371\u001b[0m from_pretrained_method \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_from_transformers \u001b[38;5;28;01mif\u001b[39;00m export \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_from_pretrained\n\u001b[0;32m--> 372\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfrom_pretrained_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/ssd-1/pythia-rlhf/venv/lib/python3.9/site-packages/optimum/onnxruntime/modeling_ort.py:570\u001b[0m, in \u001b[0;36mORTModel._from_transformers\u001b[0;34m(cls, model_id, config, use_auth_token, revision, force_download, cache_dir, subfolder, local_files_only, trust_remote_code, provider, session_options, provider_options, use_io_binding, task)\u001b[0m\n\u001b[1;32m    567\u001b[0m save_dir \u001b[38;5;241m=\u001b[39m TemporaryDirectory()\n\u001b[1;32m    568\u001b[0m save_dir_path \u001b[38;5;241m=\u001b[39m Path(save_dir\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m--> 570\u001b[0m \u001b[43mmain_export\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    572\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_dir_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_validation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[43m    \u001b[49m\u001b[43mno_post_process\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    576\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    578\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    580\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    581\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    585\u001b[0m config\u001b[38;5;241m.\u001b[39msave_pretrained(save_dir_path)\n\u001b[1;32m    586\u001b[0m maybe_save_preprocessors(model_id, save_dir_path, src_subfolder\u001b[38;5;241m=\u001b[39msubfolder)\n",
      "File \u001b[0;32m/mnt/ssd-1/pythia-rlhf/venv/lib/python3.9/site-packages/optimum/exporters/onnx/__main__.py:356\u001b[0m, in \u001b[0;36mmain_export\u001b[0;34m(model_name_or_path, output, task, opset, device, fp16, optimize, monolith, no_post_process, framework, atol, cache_dir, trust_remote_code, pad_token_id, subfolder, revision, force_download, local_files_only, use_auth_token, for_ort, do_validation, model_kwargs, custom_onnx_configs, fn_get_submodels, use_subprocess, _variant, library_name, **kwargs_shapes)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;66;03m# TODO: support onnx_config.py in the model repo\u001b[39;00m\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m custom_architecture \u001b[38;5;129;01mand\u001b[39;00m custom_onnx_configs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 356\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    357\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrying to export a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmodel_type\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m model, that is a custom or unsupported architecture for the task \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but no custom onnx configuration was passed as `custom_onnx_configs`. Please refer to https://huggingface.co/docs/optimum/main/en/exporters/onnx/usage_guides/export_a_model#custom-export-of-transformers-models for an example on how to export custom models. For the task \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, the Optimum ONNX exporter supports natively the architectures: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTasksManager\u001b[38;5;241m.\u001b[39mget_supported_model_type_for_task(task,\u001b[38;5;250m \u001b[39mexporter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124monnx\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    358\u001b[0m     )\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m custom_architecture \u001b[38;5;129;01mand\u001b[39;00m original_task \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    362\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAutomatic task detection is not supported with custom architectures. Please specify the `task` argument. Suggestion: task=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (or task=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-with-past\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m if the model is decoder-based and supports KV cache)\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    363\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Trying to export a gpt_neox model, that is a custom or unsupported architecture for the task text-classification, but no custom onnx configuration was passed as `custom_onnx_configs`. Please refer to https://huggingface.co/docs/optimum/main/en/exporters/onnx/usage_guides/export_a_model#custom-export-of-transformers-models for an example on how to export custom models. For the task text-classification, the Optimum ONNX exporter supports natively the architectures: ['albert', 'bart', 'bert', 'bloom', 'camembert', 'convbert', 'data2vec_text', 'deberta', 'deberta_v2', 'distilbert', 'electra', 'flaubert', 'ibert', 'layoutlm', 'layoutlmv3', 'lilt', 'mbart', 'mobilebert', 'mpnet', 'nystromformer', 'perceiver', 'roberta', 'roformer', 'squeezebert', 'xlm', 'xlm_roberta']."
     ]
    }
   ],
   "source": [
    "reward_model = ORTModelForSequenceClassification.from_pretrained(\n",
    "    \"usvsnsp/pythia-6.9b-rm-full-hh-rlhf\",\n",
    "    export = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "270faae1-d32a-4285-b751-2175e415f18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cf819c6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5072f569e44641289e88ce86a787a0d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/658 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94d57ca8cddb4635ace328c10fed03da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)model.bin.index.json:   0%|          | 0.00/42.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0f18ca17e25421a96d89389147c18ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "802039dab3d04061984cedda7a815144",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00001-of-00002.bin:   0%|          | 0.00/10.1G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18c4f4cbea3e4e3bbb454f87864bb74d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00002-of-00002.bin:   0%|          | 0.00/1.20G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05ce402fb3604189ba54282306dae182",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at usvsnsp/pythia-2.8b-ppo were not used when initializing GPTNeoXForCausalLM: ['v_head.2.bias', 'v_head.2.weight', 'v_head.0.bias', 'v_head.0.weight']\n",
      "- This IS expected if you are initializing GPTNeoXForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPTNeoXForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e63708ea3bc84a7b9596ad405d4283dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"usvsnsp/pythia-2.8b-ppo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4630e3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.half().eval().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "93312287",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b00addf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline('text-generation', model = model, tokenizer = tokenizer, device = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "74287edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Human: I'm looking for a new self-help book to read! Any recommendations?\n",
    "\n",
    "Assistant: Hey, I'd be happy to recommend some books.  The one I really recommend is \"A Cup of Water\" by John M. Bell, about facing our fears.  Are you looking for books on specific topics like human psychology?  There's a great book called \"Feeling Good: The New Mood Therapy\" by David Burns, about learning to feel better by understanding the reasons why we feel emotions.  It's a classic, but has been recently updated.\n",
    "\n",
    "Human: Feeling Good: The New Mood Therapy sounds great! When was it published?\n",
    "\n",
    "Assistant:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0c567d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Human: I\\'m looking for a new self-help book to read! Any recommendations?\\n\\nAssistant: Hey, I\\'d be happy to recommend some books.  The one I really recommend is \"A Cup of Water\" by John M. Bell, about facing our fears.  Are you looking for books on specific topics like human psychology?  There\\'s a great book called \"Feeling Good: The New Mood Therapy\" by David Burns, about learning to feel better by understanding the reasons why we feel emotions.  It\\'s a classic, but has been recently updated.\\n\\nHuman: Feeling Good: The New Mood Therapy sounds great! When was it published?\\n\\nAssistant: It was published in 2000, and it\\'s a classic.  It\\'s a very useful book, and it\\'s also very accessible.  It\\'s a good choice for anyone interested in improving their mood.'}]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(text, max_length = 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e386c560",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
